{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I collected data separetery so there are three types of data.\n",
    "1. aim to drive on center line.\n",
    "1. aim to drive from side to center.\n",
    "1. aim to drive smoothly.\n",
    "\n",
    "To remove noisy data, I'm going to delete some of data which seem not to fit the trend of each data.\n",
    "For example,when drive nearby left lane in second method, firstly I approched a lane line and then I steered as I approched a line enough.\n",
    "So I delete the data which steering value is saved when I approached a lane line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "driving_data_center = []\n",
    "# Load driving data\n",
    "with open(\"/home/nishi/udacity/sim_data_center/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_center.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "driving_data_additional=[]\n",
    "with open(\"/home/nishi/udacity/sim_data_additional/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_additional.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "\n",
    "driving_data_left = []\n",
    "# Load driving data\n",
    "with open(\"/home/nishi/udacity/sim_data_recovery_left/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_left.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "\n",
    "with open(\"/home/nishi/udacity/sim_data_recover_left2/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_left.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "\n",
    "driving_data_right = []\n",
    "# Load driving data\n",
    "with open(\"/home/nishi/udacity/sim_data_recovery_right/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_right.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "with open(\"/home/nishi/udacity/sim_data_recover_right2/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_right.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of driving data on left lane before delete :2934\n",
      "the number of driving data on left lane after delete :784\n",
      "the number of driving data on right lane before delete :6559\n",
      "the number of driving data on right lane after delete :2070\n",
      "(10665, 7)\n",
      "(784, 7)\n",
      "(2070, 7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# delete useless data\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "f,axes = plt.subplots(nrows=4, ncols=1,figsize=(30,10))\n",
    "\n",
    "\n",
    "# remove noisy data\n",
    "angle_data = np.array(driving_data_left)[:,3].astype(\"float\")\n",
    "n, bins, patches = axes[0].hist(angle_data, bins=25)\n",
    "print(\"the number of driving data on left lane before delete :\"+str(len(driving_data_left)))\n",
    "noise_left = np.where(np.zeros_like(angle_data)>=angle_data)\n",
    "driving_data_left=np.delete(driving_data_left,noise_left,axis=0)\n",
    "print(\"the number of driving data on left lane after delete :\"+str(len(driving_data_left)))\n",
    "\n",
    "\n",
    "# remove noisy data\n",
    "angle_data = np.array(driving_data_right)[:,3].astype(\"float\")\n",
    "n, bins, patches = axes[2].hist(angle_data, bins=25)\n",
    "print(\"the number of driving data on right lane before delete :\"+str(len(driving_data_right)))\n",
    "noise_right = np.where(np.zeros_like(angle_data)<=angle_data)\n",
    "driving_data_right=np.delete(driving_data_right,noise_right,axis=0)\n",
    "print(\"the number of driving data on right lane after delete :\"+str(len(driving_data_right)))\n",
    "\n",
    "n, bins, patches = axes[1].hist(driving_data_left[:,3].astype(\"float\"), bins=50)\n",
    "n, bins, patches = axes[3].hist(driving_data_right[:,3].astype(\"float\"), bins=50)\n",
    "print(np.shape(driving_data_center))\n",
    "print(np.shape(driving_data_left))\n",
    "print(np.shape(driving_data_right))\n",
    "driving_data=np.concatenate((driving_data_center,driving_data_left,driving_data_right,driving_data_additional),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10992, 7)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "f1,ax = plt.subplots(nrows=1,ncols=2,figsize=(30,10))\n",
    "n, bins, patches = ax[0].hist(driving_data[:,3].astype(\"float\"), bins=50)\n",
    "angle_data = np.array(driving_data)[:,3].astype(\"float\")\n",
    "n, bins, patches = axes[0].hist(angle_data, bins=25)\n",
    "print(\"The mean of samples per bin: \", int(np.mean(n)))\n",
    "print(\"the number of driving data before delete :\"+str(len(driving_data)))\n",
    "for i in range(len(n)):\n",
    "    if n[i] > (np.mean(n)+np.std(n)):\n",
    "        target = np.squeeze(np.argwhere((bins[i]<=angle_data) & (angle_data<=bins[i+1])))\n",
    "        driving_data=np.delete(driving_data,random.sample(list(target), len(target)-int(np.mean(n))),axis=0)\n",
    "print(\"the number of driving data after delete :\"+str(len(driving_data)))\n",
    "n, bins, patches = ax[1].hist(driving_data[:,3].astype(\"float\"), bins=25)\n",
    "\n",
    "# split data\n",
    "train_data, validation_data = train_test_split(driving_data, test_size=0.2) \n",
    "print(np.shape(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into image and steer angle\n",
    "# Generator which is called per batch\n",
    "from sklearn.utils import shuffle\n",
    "def driving_data_generator(input_data,batch_size): # this input does not mean network input,just generator's input.\n",
    "    data_length = len(input_data)\n",
    "    while 1:\n",
    "        shuffle(input_data)\n",
    "        for offset in range(0,data_length,batch_size):\n",
    "            batch_data = input_data[offset:offset+batch_size]\n",
    "            # hold network input and ouput data\n",
    "            images = []\n",
    "            angles = []\n",
    "            for data in batch_data:\n",
    "\n",
    "                for is_flip in range(2):\n",
    "                    if is_flip == 0:\n",
    "                        for direction in range(3):\n",
    "                            name = data[direction]\n",
    "                            image = cv2.imread(name)\n",
    "                            images.append(image)\n",
    "                            if direction == 0:\n",
    "                                angle = float(data[3])\n",
    "                            elif direction == 1:\n",
    "                                angle = float(data[3])+0.1\n",
    "                            else:\n",
    "                                angle = float(data[3])-0.1\n",
    "                            angles.append(angle)\n",
    "                    elif np.abs(float(data[3])) > 0.05:\n",
    "                        for direction in range(3):\n",
    "                            name = data[direction]\n",
    "                            image = cv2.imread(name)\n",
    "                            image = np.fliplr(image)\n",
    "                            images.append(image)\n",
    "                            if direction == 0:\n",
    "                                angle = (float(data[3]))*(-1)\n",
    "                            elif direction == 1:\n",
    "                                angle = (float(data[3])+0.1)*(-1)\n",
    "                            else:\n",
    "                                angle = (float(data[3])-0.1)*(-1)\n",
    "                            angles.append(angle)\n",
    "\n",
    "            #endfor\n",
    "            yield np.array(images),np.array(angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d (Cropping2D)      (None, 80, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 80, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 38, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 38, 158, 24)       96        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 38, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 17, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 17, 77, 36)        144       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 17, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 7, 37, 48)         192       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 5, 35, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 3, 33, 64)         256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6336)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               633700    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 771,563\n",
      "Trainable params: 771,091\n",
      "Non-trainable params: 472\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.1331\n",
      "86/86 [==============================] - 57s 666ms/step - loss: 1.4438 - val_loss: 0.1331\n",
      "Epoch 2/20\n",
      "22/22 [==============================] - 11s 488ms/step - loss: 0.1496\n",
      "86/86 [==============================] - 43s 499ms/step - loss: 0.3208 - val_loss: 0.1496\n",
      "Epoch 3/20\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.1088\n",
      "86/86 [==============================] - 44s 508ms/step - loss: 0.1605 - val_loss: 0.1088\n",
      "Epoch 4/20\n",
      "22/22 [==============================] - 10s 450ms/step - loss: 0.0678\n",
      "86/86 [==============================] - 42s 491ms/step - loss: 0.1058 - val_loss: 0.0678\n",
      "Epoch 5/20\n",
      "22/22 [==============================] - 11s 502ms/step - loss: 0.0424\n",
      "86/86 [==============================] - 44s 509ms/step - loss: 0.0808 - val_loss: 0.0424\n",
      "Epoch 6/20\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0313\n",
      "86/86 [==============================] - 44s 517ms/step - loss: 0.0649 - val_loss: 0.0313\n",
      "Epoch 7/20\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0309\n",
      "86/86 [==============================] - 42s 489ms/step - loss: 0.0567 - val_loss: 0.0309\n",
      "Epoch 8/20\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0263\n",
      "86/86 [==============================] - 44s 511ms/step - loss: 0.0499 - val_loss: 0.0263\n",
      "Epoch 9/20\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0242\n",
      "86/86 [==============================] - 43s 499ms/step - loss: 0.0448 - val_loss: 0.0242\n",
      "Epoch 10/20\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0234\n",
      "86/86 [==============================] - 43s 497ms/step - loss: 0.0414 - val_loss: 0.0234\n",
      "Epoch 11/20\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0220\n",
      "86/86 [==============================] - 44s 506ms/step - loss: 0.0376 - val_loss: 0.0220\n",
      "Epoch 12/20\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0210\n",
      "86/86 [==============================] - 43s 500ms/step - loss: 0.0345 - val_loss: 0.0210\n",
      "Epoch 13/20\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0207\n",
      "86/86 [==============================] - 45s 520ms/step - loss: 0.0328 - val_loss: 0.0207\n",
      "Epoch 14/20\n",
      "22/22 [==============================] - 11s 492ms/step - loss: 0.0196\n",
      "86/86 [==============================] - 44s 512ms/step - loss: 0.0308 - val_loss: 0.0196\n",
      "Epoch 15/20\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0196\n",
      "86/86 [==============================] - 44s 510ms/step - loss: 0.0297 - val_loss: 0.0196\n",
      "Epoch 16/20\n",
      "22/22 [==============================] - 10s 476ms/step - loss: 0.0192\n",
      "86/86 [==============================] - 42s 490ms/step - loss: 0.0280 - val_loss: 0.0192\n",
      "Epoch 17/20\n",
      "22/22 [==============================] - 10s 475ms/step - loss: 0.0190\n",
      "86/86 [==============================] - 44s 512ms/step - loss: 0.0279 - val_loss: 0.0190\n",
      "Epoch 18/20\n",
      "22/22 [==============================] - 11s 492ms/step - loss: 0.0185\n",
      "86/86 [==============================] - 43s 505ms/step - loss: 0.0259 - val_loss: 0.0185\n",
      "Epoch 19/20\n",
      "22/22 [==============================] - 10s 476ms/step - loss: 0.0185\n",
      "86/86 [==============================] - 45s 519ms/step - loss: 0.0254 - val_loss: 0.0185\n",
      "Epoch 20/20\n",
      "22/22 [==============================] - 10s 446ms/step - loss: 0.0188\n",
      "86/86 [==============================] - 42s 494ms/step - loss: 0.0245 - val_loss: 0.0188\n",
      "finish!\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "# this model is based on NVIDIA's Network https://devblogs.nvidia.com/deep-learning-self-driving-cars/\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten,Activation,Cropping2D\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "import math\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "\n",
    "## to avoid my GPU specific error.\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))\n",
    "##\n",
    "\n",
    "# Set our batch size\n",
    "batch_size=48\n",
    "height = 80\n",
    "width = 320\n",
    "channel =3\n",
    "# compile and train the model using the generator function\n",
    "train_generator = driving_data_generator(train_data, batch_size=batch_size)\n",
    "validation_generator = driving_data_generator(validation_data, batch_size=batch_size)\n",
    "# I chose elu as activation funciton ,because the authors said that is best in this paper. (https://arxiv.org/pdf/1511.07289v5.pdf)\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((60,20), (0,0)), input_shape=(160,320,3)))\n",
    "model.add(Lambda(lambda x: x/127.5-1.0, input_shape=(height,width,channel)))\n",
    "model.add(Conv2D(24,kernel_size=(5,5),strides=(2,2), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Conv2D(36,kernel_size=(5,5),strides=(2,2), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Conv2D(48,kernel_size=(5,5),strides=(2,2), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Conv2D(64,kernel_size=(3,3), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,kernel_size=(3,3), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='elu'))\n",
    "model.add(Dense(50, activation='elu'))\n",
    "model.add(Dense(10, activation='elu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit_generator(train_generator,\n",
    "            steps_per_epoch=math.ceil(len(train_data)/batch_size), \n",
    "            validation_data=validation_generator, \n",
    "            validation_steps=math.ceil(len(validation_data)/batch_size), \n",
    "            epochs=20, verbose=1)\n",
    "\n",
    "model.save('./model_20190820_ver2.h5')\n",
    "print(\"finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./run_ver2.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('./run_ver2.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d (Cropping2D)      (None, 80, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 80, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 38, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 38, 158, 24)       96        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 38, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 38, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 17, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 17, 77, 36)        144       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 17, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 7, 37, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 5, 35, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 3, 33, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6336)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               633700    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 772,163\n",
      "Trainable params: 771,391\n",
      "Non-trainable params: 772\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "99/99 [==============================] - 23s 236ms/step - loss: 0.0198\n",
      "393/393 [==============================] - 122s 311ms/step - loss: 0.2170 - val_loss: 0.0198\n",
      "Epoch 2/20\n",
      "99/99 [==============================] - 19s 191ms/step - loss: 0.0168\n",
      "393/393 [==============================] - 93s 235ms/step - loss: 0.0224 - val_loss: 0.0168\n",
      "Epoch 3/20\n",
      "99/99 [==============================] - 19s 193ms/step - loss: 0.0156\n",
      "393/393 [==============================] - 92s 235ms/step - loss: 0.0198 - val_loss: 0.0156\n",
      "Epoch 4/20\n",
      "99/99 [==============================] - 19s 193ms/step - loss: 0.0147\n",
      "393/393 [==============================] - 92s 235ms/step - loss: 0.0185 - val_loss: 0.0147\n",
      "Epoch 5/20\n",
      "99/99 [==============================] - 19s 192ms/step - loss: 0.0137\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0180 - val_loss: 0.0137\n",
      "Epoch 6/20\n",
      "99/99 [==============================] - 19s 194ms/step - loss: 0.0134\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0176 - val_loss: 0.0134\n",
      "Epoch 7/20\n",
      "99/99 [==============================] - 19s 193ms/step - loss: 0.0131\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0170 - val_loss: 0.0131\n",
      "Epoch 8/20\n",
      "99/99 [==============================] - 19s 192ms/step - loss: 0.0128\n",
      "393/393 [==============================] - 92s 235ms/step - loss: 0.0166 - val_loss: 0.0128\n",
      "Epoch 9/20\n",
      "99/99 [==============================] - 19s 192ms/step - loss: 0.0127\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0164 - val_loss: 0.0127\n",
      "Epoch 10/20\n",
      "99/99 [==============================] - 19s 193ms/step - loss: 0.0127\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0161 - val_loss: 0.0127\n",
      "Epoch 11/20\n",
      "99/99 [==============================] - 19s 194ms/step - loss: 0.0125\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0160 - val_loss: 0.0125\n",
      "Epoch 12/20\n",
      "99/99 [==============================] - 19s 195ms/step - loss: 0.0123\n",
      "393/393 [==============================] - 93s 237ms/step - loss: 0.0156 - val_loss: 0.0123\n",
      "Epoch 13/20\n",
      "99/99 [==============================] - 19s 194ms/step - loss: 0.0122\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0154 - val_loss: 0.0122\n",
      "Epoch 14/20\n",
      "99/99 [==============================] - 19s 195ms/step - loss: 0.0123\n",
      "393/393 [==============================] - 93s 237ms/step - loss: 0.0151 - val_loss: 0.0123\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 19s 192ms/step - loss: 0.0124\n",
      "393/393 [==============================] - 92s 235ms/step - loss: 0.0150 - val_loss: 0.0124\n",
      "Epoch 16/20\n",
      "99/99 [==============================] - 19s 194ms/step - loss: 0.0120\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0149 - val_loss: 0.0120\n",
      "Epoch 17/20\n",
      "99/99 [==============================] - 19s 191ms/step - loss: 0.0124\n",
      "393/393 [==============================] - 92s 235ms/step - loss: 0.0146 - val_loss: 0.0124\n",
      "Epoch 18/20\n",
      "99/99 [==============================] - 19s 194ms/step - loss: 0.0122\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0144 - val_loss: 0.0122\n",
      "Epoch 19/20\n",
      "99/99 [==============================] - 19s 193ms/step - loss: 0.0121\n",
      "393/393 [==============================] - 92s 235ms/step - loss: 0.0143 - val_loss: 0.0121\n",
      "Epoch 20/20\n",
      "99/99 [==============================] - 19s 192ms/step - loss: 0.0120\n",
      "393/393 [==============================] - 92s 235ms/step - loss: 0.0141 - val_loss: 0.0120\n",
      "finish!\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "# this model is based on NVIDIA's Network https://devblogs.nvidia.com/deep-learning-self-driving-cars/\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten,Activation,Cropping2D\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "import math\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "\n",
    "## to avoid my GPU specific error.\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))\n",
    "##\n",
    "\n",
    "# Set our batch size\n",
    "batch_size=28\n",
    "height = 80\n",
    "width = 320\n",
    "channel =3\n",
    "# compile and train the model using the generator function\n",
    "train_generator = driving_data_generator(train_data, batch_size=batch_size)\n",
    "validation_generator = driving_data_generator(validation_data, batch_size=batch_size)\n",
    "# I chose elu as activation funciton ,because the authors said that is best in this paper. (https://arxiv.org/pdf/1511.07289v5.pdf)\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((60,20), (0,0)), input_shape=(160,320,3)))\n",
    "model.add(Lambda(lambda x: x/127.5-1.0, input_shape=(height,width,channel)))\n",
    "model.add(Conv2D(24,kernel_size=(5,5),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Conv2D(36,kernel_size=(5,5),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Conv2D(48,kernel_size=(5,5),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Conv2D(64,kernel_size=(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(64,kernel_size=(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(50))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit_generator(train_generator,\n",
    "            steps_per_epoch=math.ceil(len(train_data)/batch_size), \n",
    "            validation_data=validation_generator, \n",
    "            validation_steps=math.ceil(len(validation_data)/batch_size), \n",
    "            epochs=20, verbose=1)\n",
    "\n",
    "model.save('./model_20190820_ver2_modified.h5')\n",
    "print(\"finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
