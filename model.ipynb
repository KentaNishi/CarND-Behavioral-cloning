{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I collected data separetery so there are three types of data.\n",
    "1. aim to drive on center line.\n",
    "1. aim to drive from side to center.\n",
    "1. aim to drive smoothly.\n",
    "\n",
    "To remove noisy data, I'm going to delete some of data which seem not to fit the trend of each data.\n",
    "For example,when drive nearby left lane in second method, firstly I approched a lane line and then I steered as I approched a line enough.\n",
    "So I delete the data which steering value is saved when I approached a lane line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\"/home/nishi/udacity/sim_data_recover_right2/driving_log.csv\") as csvfile:\\n    reader = csv.reader(csvfile)\\n    for data_line in reader:\\n        driving_data_right.append(data_line)\\n        \\n    #endfor\\n#endwith\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "driving_data_center = []\n",
    "# Load driving data\n",
    "with open(\"/home/nishi/udacity/sim_data_center/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_center.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "driving_data_additional=[]\n",
    "with open(\"/home/nishi/udacity/sim_data_additional/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_additional.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "\n",
    "driving_data_left = []\n",
    "# Load driving data\n",
    "with open(\"/home/nishi/udacity/sim_data_recovery_left/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_left.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "\n",
    "with open(\"/home/nishi/udacity/sim_data_recover_left2/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_left.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "\n",
    "driving_data_right = []\n",
    "# Load driving data\n",
    "with open(\"/home/nishi/udacity/sim_data_recovery_right/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_right.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "\"\"\"\n",
    "with open(\"/home/nishi/udacity/sim_data_recover_right2/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_right.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of driving data on left lane before delete :5909\n",
      "the number of driving data on left lane after delete :1472\n",
      "the number of driving data on right lane before delete :4427\n",
      "the number of driving data on right lane after delete :1466\n",
      "(10665, 7)\n",
      "(1472, 7)\n",
      "(1466, 7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# delete useless data\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "f,axes = plt.subplots(nrows=4, ncols=1,figsize=(30,10))\n",
    "\n",
    "\n",
    "# remove noisy data\n",
    "angle_data = np.array(driving_data_left)[:,3].astype(\"float\")\n",
    "n, bins, patches = axes[0].hist(angle_data, bins=25)\n",
    "print(\"the number of driving data on left lane before delete :\"+str(len(driving_data_left)))\n",
    "noise_left = np.where(np.zeros_like(angle_data)>=angle_data)\n",
    "driving_data_left=np.delete(driving_data_left,noise_left,axis=0)\n",
    "print(\"the number of driving data on left lane after delete :\"+str(len(driving_data_left)))\n",
    "\n",
    "\n",
    "# remove noisy data\n",
    "angle_data = np.array(driving_data_right)[:,3].astype(\"float\")\n",
    "n, bins, patches = axes[2].hist(angle_data, bins=25)\n",
    "print(\"the number of driving data on right lane before delete :\"+str(len(driving_data_right)))\n",
    "noise_right = np.where(np.zeros_like(angle_data)<=angle_data)\n",
    "driving_data_right=np.delete(driving_data_right,noise_right,axis=0)\n",
    "print(\"the number of driving data on right lane after delete :\"+str(len(driving_data_right)))\n",
    "\n",
    "n, bins, patches = axes[1].hist(driving_data_left[:,3].astype(\"float\"), bins=50)\n",
    "n, bins, patches = axes[3].hist(driving_data_right[:,3].astype(\"float\"), bins=50)\n",
    "print(np.shape(driving_data_center))\n",
    "print(np.shape(driving_data_left))\n",
    "print(np.shape(driving_data_right))\n",
    "driving_data=np.concatenate((driving_data_center,driving_data_left,driving_data_right,driving_data_additional),axis=0)\n",
    "#driving_data=driving_data_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11060, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f1,ax = plt.subplots(nrows=1,ncols=2,figsize=(30,10))\n",
    "n, bins, patches = ax[0].hist(driving_data[:,3].astype(\"float\"), bins=50)\n",
    "angle_data = np.array(driving_data)[:,3].astype(\"float\")\n",
    "n, bins, patches = axes[0].hist(angle_data, bins=25)\n",
    "print(\"The mean of samples per bin: \", int(np.mean(n)))\n",
    "print(\"the number of driving data before delete :\"+str(len(driving_data)))\n",
    "for i in range(len(n)):\n",
    "    if n[i] > (np.mean(n)+np.std(n)):\n",
    "        target = np.squeeze(np.argwhere((bins[i]<=angle_data) & (angle_data<=bins[i+1])))\n",
    "        driving_data=np.delete(driving_data,random.sample(list(target), len(target)-int(np.mean(n))),axis=0)\n",
    "print(\"the number of driving data after delete :\"+str(len(driving_data)))\n",
    "n, bins, patches = ax[1].hist(driving_data[:,3].astype(\"float\"), bins=25)\n",
    "\n",
    "# split data\n",
    "train_data, validation_data = train_test_split(driving_data, test_size=0.2) \n",
    "print(np.shape(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into image and steer angle\n",
    "# Generator which is called per batch\n",
    "from sklearn.utils import shuffle\n",
    "def driving_data_generator(input_data,batch_size): # this input does not mean network input,just generator's input.\n",
    "    data_length = len(input_data)\n",
    "    while 1:\n",
    "        shuffle(input_data)\n",
    "        for offset in range(0,data_length,batch_size):\n",
    "            batch_data = input_data[offset:offset+batch_size]\n",
    "            # hold network input and ouput data\n",
    "            images = []\n",
    "            angles = []\n",
    "            for data in batch_data:\n",
    "\n",
    "                for is_flip in range(2):\n",
    "                    if is_flip == 0:\n",
    "                        for direction in range(3):\n",
    "                            name = data[direction]\n",
    "                            image = cv2.imread(name)\n",
    "                            images.append(image)\n",
    "                            if direction == 0:\n",
    "                                angle = float(data[3])\n",
    "                            elif direction == 1:\n",
    "                                angle = float(data[3])+0.1\n",
    "                            else:\n",
    "                                angle = float(data[3])-0.1\n",
    "                            angles.append(angle)\n",
    "                    elif np.abs(float(data[3])) > 0.05:\n",
    "                        for direction in range(3):\n",
    "                            name = data[direction]\n",
    "                            image = cv2.imread(name)\n",
    "                            image = np.fliplr(image)\n",
    "                            images.append(image)\n",
    "                            if direction == 0:\n",
    "                                angle = (float(data[3]))*(-1)\n",
    "                            elif direction == 1:\n",
    "                                angle = (float(data[3])+0.1)*(-1)\n",
    "                            else:\n",
    "                                angle = (float(data[3])-0.1)*(-1)\n",
    "                            angles.append(angle)\n",
    "\n",
    "            #endfor\n",
    "            yield np.array(images),np.array(angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d (Cropping2D)      (None, 80, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 80, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 38, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 38, 158, 24)       96        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 38, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 17, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 17, 77, 36)        144       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 17, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 7, 37, 48)         192       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 5, 35, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 3, 33, 64)         256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6336)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               633700    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 771,563\n",
      "Trainable params: 771,091\n",
      "Non-trainable params: 472\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.1331\n",
      "86/86 [==============================] - 57s 666ms/step - loss: 1.4438 - val_loss: 0.1331\n",
      "Epoch 2/20\n",
      "22/22 [==============================] - 11s 488ms/step - loss: 0.1496\n",
      "86/86 [==============================] - 43s 499ms/step - loss: 0.3208 - val_loss: 0.1496\n",
      "Epoch 3/20\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.1088\n",
      "86/86 [==============================] - 44s 508ms/step - loss: 0.1605 - val_loss: 0.1088\n",
      "Epoch 4/20\n",
      "22/22 [==============================] - 10s 450ms/step - loss: 0.0678\n",
      "86/86 [==============================] - 42s 491ms/step - loss: 0.1058 - val_loss: 0.0678\n",
      "Epoch 5/20\n",
      "22/22 [==============================] - 11s 502ms/step - loss: 0.0424\n",
      "86/86 [==============================] - 44s 509ms/step - loss: 0.0808 - val_loss: 0.0424\n",
      "Epoch 6/20\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0313\n",
      "86/86 [==============================] - 44s 517ms/step - loss: 0.0649 - val_loss: 0.0313\n",
      "Epoch 7/20\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0309\n",
      "86/86 [==============================] - 42s 489ms/step - loss: 0.0567 - val_loss: 0.0309\n",
      "Epoch 8/20\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0263\n",
      "86/86 [==============================] - 44s 511ms/step - loss: 0.0499 - val_loss: 0.0263\n",
      "Epoch 9/20\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0242\n",
      "86/86 [==============================] - 43s 499ms/step - loss: 0.0448 - val_loss: 0.0242\n",
      "Epoch 10/20\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0234\n",
      "86/86 [==============================] - 43s 497ms/step - loss: 0.0414 - val_loss: 0.0234\n",
      "Epoch 11/20\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0220\n",
      "86/86 [==============================] - 44s 506ms/step - loss: 0.0376 - val_loss: 0.0220\n",
      "Epoch 12/20\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0210\n",
      "86/86 [==============================] - 43s 500ms/step - loss: 0.0345 - val_loss: 0.0210\n",
      "Epoch 13/20\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0207\n",
      "86/86 [==============================] - 45s 520ms/step - loss: 0.0328 - val_loss: 0.0207\n",
      "Epoch 14/20\n",
      "22/22 [==============================] - 11s 492ms/step - loss: 0.0196\n",
      "86/86 [==============================] - 44s 512ms/step - loss: 0.0308 - val_loss: 0.0196\n",
      "Epoch 15/20\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0196\n",
      "86/86 [==============================] - 44s 510ms/step - loss: 0.0297 - val_loss: 0.0196\n",
      "Epoch 16/20\n",
      "22/22 [==============================] - 10s 476ms/step - loss: 0.0192\n",
      "86/86 [==============================] - 42s 490ms/step - loss: 0.0280 - val_loss: 0.0192\n",
      "Epoch 17/20\n",
      "22/22 [==============================] - 10s 475ms/step - loss: 0.0190\n",
      "86/86 [==============================] - 44s 512ms/step - loss: 0.0279 - val_loss: 0.0190\n",
      "Epoch 18/20\n",
      "22/22 [==============================] - 11s 492ms/step - loss: 0.0185\n",
      "86/86 [==============================] - 43s 505ms/step - loss: 0.0259 - val_loss: 0.0185\n",
      "Epoch 19/20\n",
      "22/22 [==============================] - 10s 476ms/step - loss: 0.0185\n",
      "86/86 [==============================] - 45s 519ms/step - loss: 0.0254 - val_loss: 0.0185\n",
      "Epoch 20/20\n",
      "22/22 [==============================] - 10s 446ms/step - loss: 0.0188\n",
      "86/86 [==============================] - 42s 494ms/step - loss: 0.0245 - val_loss: 0.0188\n",
      "finish!\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "# this model is based on NVIDIA's Network https://devblogs.nvidia.com/deep-learning-self-driving-cars/\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten,Activation,Cropping2D\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "import math\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "\n",
    "## to avoid my GPU specific error.\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))\n",
    "##\n",
    "\n",
    "# Set our batch size\n",
    "batch_size=48\n",
    "height = 80\n",
    "width = 320\n",
    "channel =3\n",
    "# compile and train the model using the generator function\n",
    "train_generator = driving_data_generator(train_data, batch_size=batch_size)\n",
    "validation_generator = driving_data_generator(validation_data, batch_size=batch_size)\n",
    "# I chose elu as activation funciton ,because the authors said that is best in this paper. (https://arxiv.org/pdf/1511.07289v5.pdf)\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((60,20), (0,0)), input_shape=(160,320,3)))\n",
    "model.add(Lambda(lambda x: x/127.5-1.0, input_shape=(height,width,channel)))\n",
    "model.add(Conv2D(24,kernel_size=(5,5),strides=(2,2), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Conv2D(36,kernel_size=(5,5),strides=(2,2), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Conv2D(48,kernel_size=(5,5),strides=(2,2), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Conv2D(64,kernel_size=(3,3), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,kernel_size=(3,3), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='elu'))\n",
    "model.add(Dense(50, activation='elu'))\n",
    "model.add(Dense(10, activation='elu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit_generator(train_generator,\n",
    "            steps_per_epoch=math.ceil(len(train_data)/batch_size), \n",
    "            validation_data=validation_generator, \n",
    "            validation_steps=math.ceil(len(validation_data)/batch_size), \n",
    "            epochs=20, verbose=1)\n",
    "\n",
    "model.save('./model_20190820_ver2.h5')\n",
    "print(\"finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./run_ver2.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('./run_ver2.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d (Cropping2D)      (None, 80, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 80, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 38, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 38, 158, 24)       96        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 38, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 38, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 17, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 17, 77, 36)        144       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 17, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 7, 37, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 5, 35, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 3, 33, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6336)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               633700    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 772,163\n",
      "Trainable params: 771,391\n",
      "Non-trainable params: 772\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "99/99 [==============================] - 23s 236ms/step - loss: 0.0198\n",
      "393/393 [==============================] - 122s 311ms/step - loss: 0.2170 - val_loss: 0.0198\n",
      "Epoch 2/20\n",
      "99/99 [==============================] - 19s 191ms/step - loss: 0.0168\n",
      "393/393 [==============================] - 93s 235ms/step - loss: 0.0224 - val_loss: 0.0168\n",
      "Epoch 3/20\n",
      "99/99 [==============================] - 19s 193ms/step - loss: 0.0156\n",
      "393/393 [==============================] - 92s 235ms/step - loss: 0.0198 - val_loss: 0.0156\n",
      "Epoch 4/20\n",
      "99/99 [==============================] - 19s 193ms/step - loss: 0.0147\n",
      "393/393 [==============================] - 92s 235ms/step - loss: 0.0185 - val_loss: 0.0147\n",
      "Epoch 5/20\n",
      "99/99 [==============================] - 19s 192ms/step - loss: 0.0137\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0180 - val_loss: 0.0137\n",
      "Epoch 6/20\n",
      "99/99 [==============================] - 19s 194ms/step - loss: 0.0134\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0176 - val_loss: 0.0134\n",
      "Epoch 7/20\n",
      "99/99 [==============================] - 19s 193ms/step - loss: 0.0131\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0170 - val_loss: 0.0131\n",
      "Epoch 8/20\n",
      "99/99 [==============================] - 19s 192ms/step - loss: 0.0128\n",
      "393/393 [==============================] - 92s 235ms/step - loss: 0.0166 - val_loss: 0.0128\n",
      "Epoch 9/20\n",
      "99/99 [==============================] - 19s 192ms/step - loss: 0.0127\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0164 - val_loss: 0.0127\n",
      "Epoch 10/20\n",
      "99/99 [==============================] - 19s 193ms/step - loss: 0.0127\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0161 - val_loss: 0.0127\n",
      "Epoch 11/20\n",
      "99/99 [==============================] - 19s 194ms/step - loss: 0.0125\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0160 - val_loss: 0.0125\n",
      "Epoch 12/20\n",
      "99/99 [==============================] - 19s 195ms/step - loss: 0.0123\n",
      "393/393 [==============================] - 93s 237ms/step - loss: 0.0156 - val_loss: 0.0123\n",
      "Epoch 13/20\n",
      "99/99 [==============================] - 19s 194ms/step - loss: 0.0122\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0154 - val_loss: 0.0122\n",
      "Epoch 14/20\n",
      "99/99 [==============================] - 19s 195ms/step - loss: 0.0123\n",
      "393/393 [==============================] - 93s 237ms/step - loss: 0.0151 - val_loss: 0.0123\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 19s 192ms/step - loss: 0.0124\n",
      "393/393 [==============================] - 92s 235ms/step - loss: 0.0150 - val_loss: 0.0124\n",
      "Epoch 16/20\n",
      "99/99 [==============================] - 19s 194ms/step - loss: 0.0120\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0149 - val_loss: 0.0120\n",
      "Epoch 17/20\n",
      "99/99 [==============================] - 19s 191ms/step - loss: 0.0124\n",
      "393/393 [==============================] - 92s 235ms/step - loss: 0.0146 - val_loss: 0.0124\n",
      "Epoch 18/20\n",
      "99/99 [==============================] - 19s 194ms/step - loss: 0.0122\n",
      "393/393 [==============================] - 93s 236ms/step - loss: 0.0144 - val_loss: 0.0122\n",
      "Epoch 19/20\n",
      "99/99 [==============================] - 19s 193ms/step - loss: 0.0121\n",
      "393/393 [==============================] - 92s 235ms/step - loss: 0.0143 - val_loss: 0.0121\n",
      "Epoch 20/20\n",
      "99/99 [==============================] - 19s 192ms/step - loss: 0.0120\n",
      "393/393 [==============================] - 92s 235ms/step - loss: 0.0141 - val_loss: 0.0120\n",
      "finish!\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "# this model is based on NVIDIA's Network https://devblogs.nvidia.com/deep-learning-self-driving-cars/\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten,Activation,Cropping2D\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "import math\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "\n",
    "## to avoid my GPU specific error.\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))\n",
    "##\n",
    "\n",
    "# Set our batch size\n",
    "batch_size=28\n",
    "height = 80\n",
    "width = 320\n",
    "channel =3\n",
    "# compile and train the model using the generator function\n",
    "train_generator = driving_data_generator(train_data, batch_size=batch_size)\n",
    "validation_generator = driving_data_generator(validation_data, batch_size=batch_size)\n",
    "# I chose elu as activation funciton ,because the authors said that is best in this paper. (https://arxiv.org/pdf/1511.07289v5.pdf)\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((60,20), (0,0)), input_shape=(160,320,3)))\n",
    "model.add(Lambda(lambda x: x/127.5-1.0, input_shape=(height,width,channel)))\n",
    "model.add(Conv2D(24,kernel_size=(5,5),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Conv2D(36,kernel_size=(5,5),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Conv2D(48,kernel_size=(5,5),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Conv2D(64,kernel_size=(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(64,kernel_size=(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(50))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit_generator(train_generator,\n",
    "            steps_per_epoch=math.ceil(len(train_data)/batch_size), \n",
    "            validation_data=validation_generator, \n",
    "            validation_steps=math.ceil(len(validation_data)/batch_size), \n",
    "            epochs=20, verbose=1)\n",
    "\n",
    "model.save('./model_20190820_ver2_modified.h5')\n",
    "print(\"finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_1 (Cropping2D)    (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 33, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 33, 158, 24)       96        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 33, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 15, 77, 36)        144       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 6, 37, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 6, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 4, 35, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 2, 33, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4224)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               422500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 560,963\n",
      "Trainable params: 560,191\n",
      "Non-trainable params: 772\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "43/43 [==============================] - 16s 361ms/step - loss: 0.0501\n",
      "169/169 [==============================] - 74s 438ms/step - loss: 0.1015 - val_loss: 0.0501\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 16s 361ms/step - loss: 0.0284\n",
      "169/169 [==============================] - 70s 417ms/step - loss: 0.0200 - val_loss: 0.0284\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 16s 361ms/step - loss: 0.0255\n",
      "169/169 [==============================] - 70s 416ms/step - loss: 0.0176 - val_loss: 0.0255\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 15s 360ms/step - loss: 0.0259\n",
      "169/169 [==============================] - 70s 416ms/step - loss: 0.0163 - val_loss: 0.0259\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 16s 361ms/step - loss: 0.0261\n",
      "169/169 [==============================] - 71s 418ms/step - loss: 0.0153 - val_loss: 0.0261\n",
      "finish!\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "# this model is based on NVIDIA's Network https://devblogs.nvidia.com/deep-learning-self-driving-cars/\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten,Activation,Cropping2D\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "import math\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "\n",
    "## to avoid my GPU specific error.\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))\n",
    "##\n",
    "\n",
    "# Set our batch size\n",
    "batch_size=28\n",
    "height = 70\n",
    "width = 320\n",
    "channel =3\n",
    "# compile and train the model using the generator function\n",
    "train_generator = driving_data_generator(train_data, batch_size=batch_size)\n",
    "validation_generator = driving_data_generator(validation_data, batch_size=batch_size)\n",
    "# I chose elu as activation funciton ,because the authors said that is best in this paper. (https://arxiv.org/pdf/1511.07289v5.pdf)\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((70,20), (0,0)), input_shape=(160,320,3)))\n",
    "model.add(Lambda(lambda x: x/127.5-1.0, input_shape=(height,width,channel)))\n",
    "model.add(Conv2D(24,kernel_size=(5,5),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(36,kernel_size=(5,5),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(48,kernel_size=(5,5),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(64,kernel_size=(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(64,kernel_size=(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dense(50))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit_generator(train_generator,\n",
    "            steps_per_epoch=math.ceil(len(train_data)/batch_size), \n",
    "            validation_data=validation_generator, \n",
    "            validation_steps=math.ceil(len(validation_data)/batch_size), \n",
    "            epochs=10,callbacks=[EarlyStopping(patience=2)], verbose=1)\n",
    "\n",
    "model.save('./model_20190820_without_dropout.h5')\n",
    "print(\"finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d (Cropping2D)      (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 33, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 33, 158, 24)       96        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 33, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 15, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 15, 77, 36)        144       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 15, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 6, 37, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 6, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 4, 35, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 2, 33, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4224)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               422500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 560,963\n",
      "Trainable params: 560,191\n",
      "Non-trainable params: 772\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/nishi/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "99/99 [==============================] - 41s 417ms/step - loss: 0.0209\n",
      "395/395 [==============================] - 205s 520ms/step - loss: 0.0451 - val_loss: 0.0209\n",
      "Epoch 2/10\n",
      "99/99 [==============================] - 35s 349ms/step - loss: 0.0151\n",
      "395/395 [==============================] - 167s 423ms/step - loss: 0.0168 - val_loss: 0.0151\n",
      "Epoch 3/10\n",
      "99/99 [==============================] - 35s 351ms/step - loss: 0.0137\n",
      "395/395 [==============================] - 167s 422ms/step - loss: 0.0154 - val_loss: 0.0137\n",
      "Epoch 4/10\n",
      "99/99 [==============================] - 34s 346ms/step - loss: 0.0132\n",
      "395/395 [==============================] - 164s 416ms/step - loss: 0.0144 - val_loss: 0.0132\n",
      "Epoch 5/10\n",
      "99/99 [==============================] - 34s 345ms/step - loss: 0.0133\n",
      "395/395 [==============================] - 164s 416ms/step - loss: 0.0137 - val_loss: 0.0133\n",
      "Epoch 6/10\n",
      "99/99 [==============================] - 34s 348ms/step - loss: 0.0135\n",
      "395/395 [==============================] - 164s 416ms/step - loss: 0.0130 - val_loss: 0.0135\n",
      "finish!\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "# this model is based on NVIDIA's Network https://devblogs.nvidia.com/deep-learning-self-driving-cars/\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten,Activation,Cropping2D\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "import math\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "\n",
    "## to avoid my GPU specific error.\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))\n",
    "##\n",
    "\n",
    "# Set our batch size\n",
    "batch_size=28\n",
    "height = 70\n",
    "width = 320\n",
    "channel =3\n",
    "# compile and train the model using the generator function\n",
    "train_generator = driving_data_generator(train_data, batch_size=batch_size)\n",
    "validation_generator = driving_data_generator(validation_data, batch_size=batch_size)\n",
    "# I chose elu as activation funciton ,because the authors said that is best in this paper. (https://arxiv.org/pdf/1511.07289v5.pdf)\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((70,20), (0,0)), input_shape=(160,320,3)))\n",
    "model.add(Lambda(lambda x: x/127.5-1.0, input_shape=(height,width,channel)))\n",
    "model.add(Conv2D(24,kernel_size=(5,5),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(36,kernel_size=(5,5),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(48,kernel_size=(5,5),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(64,kernel_size=(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(64,kernel_size=(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dense(50))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit_generator(train_generator,\n",
    "            steps_per_epoch=math.ceil(len(train_data)/batch_size), \n",
    "            validation_data=validation_generator, \n",
    "            validation_steps=math.ceil(len(validation_data)/batch_size), \n",
    "            epochs=10,callbacks=[EarlyStopping(patience=2)], verbose=1)\n",
    "\n",
    "model.save('./model_without_distribution_change.h5')\n",
    "print(\"finish!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the parameter which express the ratio of data derived from each data-set.\n",
    "\n",
    "alpha: the number of data driving in side lane / the number of data driving in center lane.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\"/home/nishi/udacity/sim_data_recover_right2/driving_log.csv\") as csvfile:\\n    reader = csv.reader(csvfile)\\n    for data_line in reader:\\n        driving_data_right.append(data_line)\\n        \\n    #endfor\\n#endwith\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "alpha = np.arange(2,10,1)/10\n",
    "driving_data_center = []\n",
    "# Load driving data\n",
    "with open(\"/home/nishi/udacity/sim_data_center/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_center.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "\"\"\"\n",
    "driving_data_additional=[]\n",
    "with open(\"/home/nishi/udacity/sim_data_additional/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_additional.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "\"\"\"\n",
    "\n",
    "driving_data_left = []\n",
    "# Load driving data\n",
    "with open(\"/home/nishi/udacity/sim_data_recovery_left/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_left.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "\n",
    "with open(\"/home/nishi/udacity/sim_data_recover_left2/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_left.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "\n",
    "driving_data_right = []\n",
    "# Load driving data\n",
    "with open(\"/home/nishi/udacity/sim_data_recovery_right/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_right.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "\"\"\"\n",
    "with open(\"/home/nishi/udacity/sim_data_recover_right2/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for data_line in reader:\n",
    "        driving_data_right.append(data_line)\n",
    "        \n",
    "    #endfor\n",
    "#endwith\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of driving data on left lane before delete :5909\n",
      "the number of driving data on left lane after delete :1472\n",
      "the number of driving data on right lane before delete :4427\n",
      "the number of driving data on right lane after delete :1466\n",
      "(10665, 7)\n",
      "(1472, 7)\n",
      "(1466, 7)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABrwAAAJCCAYAAACS+2eoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3X+QZWd5H/jvgybCibHNiJloZUnQSnacmDhZYKcELrZiGYEQaAvJZVYWFduDo2TyA9nJYu8yJH8oBeuqcZyY4CqHeIIURMpGyLK9mo3kaBUZ4krKUjSyMSApWBMxWDMRaLCAJEUFW+bZP/qM9zKaUd/p7ntvn76fT1VXn/Oe997z3Jl+z7l9v33eU90dAAAAAAAAGKsXLLoAAAAAAAAA2AiBFwAAAAAAAKMm8AIAAAAAAGDUBF4AAAAAAACMmsALAAAAAACAURN4AQAAAAAAMGoCLwAAAAAAAEZN4AUAAAAAAMCoCbwAAAAAAAAYtR2LLuD57Nq1q1dWVhZdBgAAAAAAAHP28MMPf7G7d0/Td0sHXisrKzly5MiiywAAAAAAAGDOqupz0/Y1pSEAAAAAAACjJvACAAAAAABg1AReAAAAAAAAjJrACwAAAAAAgFHbsegCAAAA2HpWDty96BLm7tjBaxZdAgAAsE6u8AIAAAAAAGDUBF4AAAAAAACMmsALAAAAAACAURN4AQAAAAAAMGoCLwAAAAAAAEZN4AUAAAAAAMCoCbwAAAAAAAAYNYEXAAAAAAAAoybwAgAAAAAAYNQEXgAAAAAAAIyawAsAAAAAAIBRE3gBAAAAAAAwagIvAAAAAAAARm3NwKuqLq2qj1XVo1X1SFX9naH9gqq6r6oeH77vHNqrqn62qo5W1Ser6lUTz7Vv6P94Ve2b3csCAAAAAABgWUxzhdezSX68u1+e5DVJ3lFVL09yIMn93b0nyf3DepK8Kcme4Wt/kg8kqwFZkpuTvDrJ5UluPhWSAQAAAAAAwHqtGXh191Pd/VvD8n9N8liSi5Ncm+S2odttSa4blq9N8uFe9UCSF1fVRUnemOS+7n6mu7+U5L4kV2/qqwEAAAAAAGDpnNM9vKpqJckrkzyY5MLufmrY9PkkFw7LFyd5cuJhx4e2s7UDAAAAAADAuk0deFXVi5L8cpK/293/ZXJbd3eS3oyCqmp/VR2pqiMnT57cjKcEAAAAAABgG5sq8KqqP5HVsOsXuvtXhuYvDFMVZvj+9NB+IsmlEw+/ZGg7W/s36O5D3b23u/fu3r37XF4LAAAAAAAAS2jNwKuqKsktSR7r7p+Z2HQ4yb5heV+Suybaf7hWvSbJV4apD+9NclVV7ayqnUmuGtoAAAAAAABg3XZM0ee1SX4oyaeq6hND299LcjDJHVV1Y5LPJbl+2HZPkjcnOZrkq0l+JEm6+5mqem+Sh4Z+7+nuZzblVQAAAAAAALC01gy8uvvfJamzbL7yDP07yTvO8ly3Jrn1XAoEAAAAAACA5zPVPbwAAAAAAABgqxJ4AQAAAAAAMGoCLwAAAAAAAEZN4AUAAAAAAMCoCbwAAAAAAAAYNYEXAAAAAAAAoybwAgAAAAAAYNQEXgAAAAAAAIyawAsAAAAAAIBRE3gBAAAAAAAwagIvAAAAAAAARk3gBQAAAAAAwKgJvAAAAAAAABg1gRcAAAAAAACjJvACAAAAAABg1AReAAAAAAAAjJrACwAAAAAAgFETeAEAAAAAADBqAi8AAAAAAABGTeAFAAAAAADAqAm8AAAAAAAAGDWBFwAAAAAAAKMm8AIAAAAAAGDUBF4AAAAAAACMmsALAAAAAACAURN4AQAAAAAAMGoCLwAAAAAAAEZN4AUAAAAAAMCoCbwAAAAAAAAYNYEXAAAAAAAAoybwAgAAAAAAYNQEXgAAAAAAAIyawAsAAAAAAIBRE3gBAAAAAAAwagIvAAAAAAAARk3gBQAAAAAAwKgJvAAAAAAAABg1gRcAAAAAAACjJvACAAAAAABg1NYMvKrq1qp6uqo+PdF2QVXdV1WPD993Du1VVT9bVUer6pNV9aqJx+wb+j9eVftm83IAAAAAAABYNtNc4fWhJFef1nYgyf3dvSfJ/cN6krwpyZ7ha3+SDySrAVmSm5O8OsnlSW4+FZIBAAAAAADARqwZeHX3byR55rTma5PcNizfluS6ifYP96oHkry4qi5K8sYk93X3M939pST35bkhGgAAAAAAAJyz9d7D68LufmpY/nySC4fli5M8OdHv+NB2tvbnqKr9VXWkqo6cPHlyneUBAAAAAACwLNYbeP2x7u4kvQm1nHq+Q929t7v37t69e7OeFgAAAAAAgG1qvYHXF4apCjN8f3poP5Hk0ol+lwxtZ2sHAAAAAACADVlv4HU4yb5heV+Suybaf7hWvSbJV4apD+9NclVV7ayqnUmuGtoAAAAAAABgQ3as1aGqPpLkiiS7qup4kpuTHExyR1XdmORzSa4fut+T5M1Jjib5apIfSZLufqaq3pvkoaHfe7r7mU18HQAAAAAAACypNQOv7n7bWTZdeYa+neQdZ3meW5Pcek7VAQAAAAAAwBrWO6UhAAAAAAAAbAkCLwAAAAAAAEZN4AUAAAAAAMCoCbwAAAAAAAAYNYEXAAAAAAAAoybwAgAAAAAAYNQEXgAAAAAAAIyawAsAAAAAAIBRE3gBAAAAAAAwagIvAAAAAAAARk3gBQAAAAAAwKgJvAAAAAAAABg1gRcAAAAAAACjJvACAAAAAABg1AReAAAAAAAAjJrACwAAAAAAgFETeAEAAAAAADBqOxZdAAAAjNnKgbsXXcLcHTt4zaJLAAAAgG/gCi8AAAAAAABGTeAFAAAAAADAqJnSEACATbOM0/sBAAAAi+cKLwAAAAAAAEZN4AUAAAAAAMCoCbwAAAAAAAAYNYEXAAAAAAAAoybwAgAAAAAAYNR2LLoAAIDtbOXA3YsuAQAAAGDbE3gBAADnZBmD3GMHr1l0CQAAADwPUxoCAAAAAAAwaq7wAgAAWMMyXtUGAAAwJgIvAAAAiGCT7cmUrADAshB4AQBz44NEAID5Wsb3X0I+AFhO7uEFAAAAAADAqAm8AAAAAAAAGDWBFwAAAAAAAKPmHl4AAAAAbBvuWwYAy8kVXgAAAAAAAIyaK7wAAAAAYMRc1QYACwi8qurqJO9Pcl6SD3b3wXnXAAAAAACMl5APgNPNNfCqqvOS/FySNyQ5nuShqjrc3Y/Osw4Atp5l/GUFAAAAANgc877C6/IkR7v7iSSpqtuTXJtE4AUwQfgDAAAATFrGzwpc1Qaci3kHXhcneXJi/XiSV092qKr9SfYPq/+tqj4zp9oWZVeSLy66CBgxYwjWz/iBjTGGYP2MH9gYYwg2xhgaifqpRVfAGRg/zNvLpu0493t4raW7DyU5tOg65qWqjnT33kXXAWNlDMH6GT+wMcYQrJ/xAxtjDMHGGEOwfsYPW9kL5ry/E0kunVi/ZGgDAAAAAACAdZl34PVQkj1VdVlVnZ/khiSH51wDAAAAAAAA28hcpzTs7mer6qYk9yY5L8mt3f3IPGvYgpZm+kaYEWMI1s/4gY0xhmD9jB/YGGMINsYYgvUzftiyqrsXXQMAAAAAAACs27ynNAQAAAAAAIBNJfACAAAAAABg1ARec1BV/1tVPVJVX6+qvc/T7+qq+kxVHa2qAxPtl1XVg0P7R6vq/PlUDotXVRdU1X1V9fjwfecZ+nxvVX1i4uu/V9V1w7YPVdVnJ7a9Yv6vAhZnmjE09PujiXFyeKLdOYilNuV56BVV9ZvD+71PVtUPTGxzHmLpnO33montLxzOKUeHc8zKxLZ3D+2fqao3zrNu2CqmGEPvrKpHh3PO/VX1soltZ3xPB8tiivHz9qo6OTFO/trEtn3De77Hq2rffCuHrWGKMfS+ifHzu1X15YltzkEsnHt4zUFVfWeSryf5+SQ/0d1HztDnvCS/m+QNSY4neSjJ27r70aq6I8mvdPftVfXPkvxOd39gfq8AFqeq/mGSZ7r74HCi3dnd73qe/hckOZrkku7+alV9KMm/6u4751MxbC3TjqGq+m/d/aIztDsHsdSmGUNV9R1Jursfr6pvT/Jwku/s7i87D7Fsnu/3mok+fzvJX+ruv1lVNyT5vu7+gap6eZKPJLk8ybcn+TdJvqO7/2jerwMWZcox9L1JHhx+3/lbSa7o7h8Ytp3xPR0sgynHz9uT7O3um0577AVJjiTZm6Sz+n7uf+7uL82neli8acbQaf1/NMkru/uvDuvOQSycK7zmoLsf6+7PrNHt8iRHu/uJ7v6DJLcnubaqKsnrkpz6kOS2JNfNrlrYcq7N6s99Mt3P/1uT/Fp3f3WmVcF4nOsY+mPOQZBkijHU3b/b3Y8Py/85ydNJds+tQthazvh7zWl9JsfVnUmuHM451ya5vbu/1t2fzeofMV0+p7phq1hzDHX3xyZ+33kgySVzrhG2qmnOQWfzxiT3dfczQ8h1X5KrZ1QnbFXnOobeltU/VoItQ+C1dVyc5MmJ9eND20uSfLm7nz2tHZbFhd391LD8+SQXrtH/hjz3ZPuTw3Qf76uqF256hbC1TTuGvqmqjlTVAzVMCRrnIEjO8TxUVZcnOT/Jf5podh5imZzt95oz9hnOMV/J6jlnmsfCdneu4+DGJL82sX6m93SwLKYdP98/vDe7s6ouPcfHwnY29TgYptO9LMmvTzQ7B7FwOxZdwHZRVf8myf9whk1/v7vvmnc9MCbPN34mV7q7q+qs87BW1UVJ/mKSeyea353VDyjPT3IoybuSvGejNcNWsklj6GXdfaKq/kySX6+qT2X1A0jY9jb5PPQvk+zr7q8Pzc5DAMxEVf1gVqdf+56J5ue8p+vu/3TmZ4Cl9P8k+Uh3f62q/kZWrzh+3YJrgjG6Icmdp0097RzEwgm8Nkl3v36DT3EiyaUT65cMbb+f5MVVtWP468dT7bBtPN/4qaovVNVF3f3U8EHi08/zVNcn+dXu/sOJ5z71V/lfq6p/keQnNqVo2EI2Ywx194nh+xNV9fEkr0zyy3EOYglsxhiqqm9NcndW/9jpgYnndh5i2Zzt95oz9TleVTuSfFtWf++Z5rGw3U01Dqrq9Vn9w4zv6e6vnWo/y3s6HzayLNYcP939+xOrH0zyDycee8Vpj/34plcIW9u5vBe7Ick7Jhucg9gKTGm4dTyUZE9VXVZV52f1oHG4uzvJx7J6X6Ik2ZfEFWMsk8NZ/blP1v75f87cwcOHk6fuRXRdkk/PoEbYytYcQ1W189Q0a1W1K8lrkzzqHARJphtD5yf51SQf7u47T9vmPMSyOePvNaf1mRxXb03y68M553CSG6rqhVV1WZI9Sf7DnOqGrWLNMVRVr0zy80ne0t1PT7Sf8T3d3CqHxZtm/Fw0sfqWJI8Ny/cmuWoYRzuTXJVvnD0GlsE07+NSVX8+yc4kvznR5hzEliDwmoOq+r6qOp7ku5PcXVX3Du3fXlX3JH88d/1NWT2ZPpbkju5+ZHiKdyV5Z1Udzerc9rfM+zXAAh1M8oaqejzJ64f1VNXeqvrgqU5VtZLVv0L5t6c9/heGqdk+lWRXkv9rDjXDVjLNGPrOJEeq6neyGnAd7O5Tb0ydg1h204yh65P85SRvr6pPDF+vGLY5D7FUzvZ7TVW9p6reMnS7JclLhnPLO5McGB77SJI7svrhyL9O8o7TpsmBbW/KMfTTSV6U5JeGc86pDyOf7z0dbHtTjp8fq6pHhnHyY0nePjz2mSTvzeoH/g8lec/QBktjyjGUrAZhtw9/sHSKcxBbQn3jzyUAAAAAAACMiyu8AAAAAAAAGDWBFwAAAAAAAKMm8AIAAAAAAGDUBF4AAAAAAACMmsALAAAAAACAURN4AQAAAAAAMGoCLwAAAAAAAEZtx6ILeD67du3qlZWVRZcBAAAAAADAnD388MNf7O7d0/Td0oHXyspKjhw5sugyAAAAAAAAmLOq+ty0fU1pCAAAAAAAwKgJvAAAAAAAABg1gRcAAAAAAACjJvACAAAAAABg1HYsugA218qBuxey32MHr1nIfgEAAAAAAFzhBQAAAAAAwKgJvAAAAAAAABg1UxoCsNQWNRVsYjpYAAAAANgsrvACAAAAAABg1AReAAAAAAAAjJrACwAAAAAAgFETeAEAAAAAADBqAi8AAAAAAABGTeAFAAAAAADAqM0s8Kqq/72qHqmqT1fVR6rqm6rqsqp6sKqOVtVHq+r8We0fAAAAAACA5TCTwKuqLk7yY0n2dvd3JTkvyQ1JfirJ+7r7f0zypSQ3zmL/AAAAAAAALI9ZTmm4I8mfrKodSf5UkqeSvC7JncP225JcN8P9AwAAAAAAsARmEnh194kk/yjJ72U16PpKkoeTfLm7nx26HU9y8emPrar9VXWkqo6cPHlyFuUBAAAAAACwjcxqSsOdSa5NclmSb0/yzUmunuax3X2ou/d2997du3fPojwAAAAAAAC2kVlNafj6JJ/t7pPd/YdJfiXJa5O8eJjiMEkuSXJiRvsHAAAAAABgScwq8Pq9JK+pqj9VVZXkyiSPJvlYkrcOffYluWtG+wcAAAAAAGBJzOoeXg8muTPJbyX51LCfQ0neleSdVXU0yUuS3DKL/QMAAAAAALA8dqzdZX26++YkN5/W/ESSy2e1TwAAAAAAAJbPrKY0BAAAAAAAgLkQeAEAAAAAADBqM5vSELa7lQN3L2S/xw5es5D9AgAAAADAVuUKLwAAAAAAAEbNFV7Alreoq+kSV9QBAAAAAIyBK7wAAAAAAAAYNYEXAAAAAAAAoybwAgAAAAAAYNQEXgAAAAAAAIyawAsAAAAAAIBRE3gBAAAAAAAwagIvAAAAAAAARk3gBQAAAAAAwKgJvAAAAAAAABi1HYsuAIDnWjlw90L2e+zgNQvZLwAAAADARszsCq+qenFV3VlV/7GqHquq766qC6rqvqp6fPi+c1b7BwAAAAAAYDnMckrD9yf5193955P8T0keS3Igyf3dvSfJ/cM6AAAAAAAArNtMAq+q+rYkfznJLUnS3X/Q3V9Ocm2S24ZutyW5bhb7BwAAAAAAYHnM6gqvy5KcTPIvquq3q+qDVfXNSS7s7qeGPp9PcuGM9g8AAAAAAMCS2DHD531Vkh/t7ger6v05bfrC7u6q6tMfWFX7k+xPkpe+9KUzKg8AYD5WDty9kP0eO3jNQvYLAAAAsAizCryOJzne3Q8O63dmNfD6QlVd1N1PVdVFSZ4+/YHdfSjJoSTZu3fvcwIxmLSoDxEBAAAAAICtYyZTGnb355M8WVV/bmi6MsmjSQ4n2Te07Uty1yz2DwAAAAAAwPKY1RVeSfKjSX6hqs5P8kSSH8lqwHZHVd2Y5HNJrp/h/gEAAAAAAFgCMwu8uvsTSfaeYdOVs9onAAAAAAAAy2eWV3gBALAgi7rP5bGD1yxkvwAAAMBym8k9vAAAAAAAAGBeBF4AAAAAAACMmsALAAAAAACAURN4AQAAAAAAMGoCLwAAAAAAAEZtx6ILAADma+XA3YsuYe6OHbxm0SUsjUX+fPl/BgAAgOXlCi8AAAAAAABGTeAFAAAAAADAqJnSEIAtYRmn2QMAAAAANofACwCAbWFRwbl7hwEAAMDiCbzYFK7MmJ9F/lv7QA8AAAAAgK1I4AUAbHv+MAMAAABge3vBogsAAAAAAACAjRB4AQAAAAAAMGqmNASmZkowAAAAAAC2opld4VVV51XVb1fVvxrWL6uqB6vqaFV9tKrOn9W+AQAAAAAAWB6zvMLr7yR5LMm3Dus/leR93X17Vf2zJDcm+cAM9w8AW5qrJmF7WORYPnbwmoXtGwAAALaSmVzhVVWXJLkmyQeH9UryuiR3Dl1uS3LdLPYNAAAAAADAcpnVlIb/JMn/meTrw/pLkny5u58d1o8nuXhG+wYAAAAAAGCJbHrgVVX/a5Knu/vhdT5+f1UdqaojJ0+e3OTqAAAAAAAA2G5mcYXXa5O8paqOJbk9q1MZvj/Ji6vq1D3DLkly4kwP7u5D3b23u/fu3r17BuUBAAAAAACwnexYu8u56e53J3l3klTVFUl+orv/SlX9UpK3ZjUE25fkrs3eNwAbs3Lg7kWXAAAAAABwzmZ1D68zeVeSd1bV0aze0+uWOe4bAAAAAACAbWrTr/Ca1N0fT/LxYfmJJJfPcn8AAAAAAAAsn5kGXgBjZ4o/AAAAAICtb55TGgIAAAAAAMCmE3gBAAAAAAAwagIvAAAAAAAARk3gBQAAAAAAwKgJvAAAAAAAABg1gRcAAAAAAACjJvACAAAAAABg1HYsugAAAADObOXA3Qvb97GD1yxs3wAAAOfKFV4AAAAAAACMmiu8AACAc+KqIwAAALYaV3gBAAAAAAAwagIvAAAAAAAARs2UhgAAAGwZpsxcDv6fAQDYbAIvAABgNBb1IbkPyJeDny8AABgvUxoCAAAAAAAwajO5wquqLk3y4SQXJukkh7r7/VV1QZKPJllJcizJ9d39pVnUAAAAsFkWOf0aAAAAa5vVFV7PJvnx7n55ktckeUdVvTzJgST3d/eeJPcP6wAAAAAAALBuMwm8uvup7v6tYfm/JnksycVJrk1y29DttiTXzWL/AAAAAAAALI+ZTGk4qapWkrwyyYNJLuzup4ZNn8/qlIen99+fZH+SvPSlL511eQAAMFqm2QMAAIBVs5rSMElSVS9K8stJ/m53/5fJbd3dWb2/V05rP9Tde7t77+7du2dZHgAAAAAAANvAzAKvqvoTWQ27fqG7f2Vo/kJVXTRsvyjJ07PaPwAAAAAAAMthJoFXVVWSW5I81t0/M7HpcJJ9w/K+JHfNYv8AAAAAAAAsj1ndw+u1SX4oyaeq6hND299LcjDJHVV1Y5LPJbl+RvsHAABgA9wjbn4W+W997OA1C9s3AABsppkEXt3975LUWTZfOYt9AgAAAAAAsJxmdg8vAAAAAAAAmAeBFwAAAAAAAKMm8AIAAAAAAGDUBF4AAAAAAACMmsALAAAAAACAURN4AQAAAAAAMGo7Fl0AAAAAwLysHLh7Ifs9dvCahewXADgz7wm2H4EXAAAAwIz5UA0AYLYEXgAAAADb1KKCtkTYBgDMl8ALAAAAltQiwxDYjlzJBwCL84JFFwAAAAAAAAAbIfACAAAAAABg1AReAAAAAAAAjJp7eAEAAAAA6+K+ZQBsFQIvAAAAALaNRQUwi7SMrxlmaZFjSpgL6yfwAgAAAACYgiAENpfAns0093t4VdXVVfWZqjpaVQfmvX8AAAAAAAC2l7le4VVV5yX5uSRvSHI8yUNVdbi7H51nHQAAAADMlr/aBzbKcQQ4F/O+wuvyJEe7+4nu/oMktye5ds41AAAAAAAAsI1Ud89vZ1VvTXJ1d/+1Yf2Hkry6u2+a6LM/yf5h9c8l+czcCty6diX54qKLAOCsHKcBtjbHaYCtyzEaYGtznGbRXtbdu6fpONcpDafR3YeSHFp0HVtJVR3p7r2LrgOAM3OcBtjaHKcBti7HaICtzXGaMZn3lIYnklw6sX7J0AYAAAAAAADrMu/A66Eke6rqsqo6P8kNSQ7PuQYAAAAAAAC2kblOadjdz1bVTUnuTXJeklu7+5F51jBSpngE2NocpwG2NsdpgK3LMRpga3OcZjSquxddAwAAAAAAAKzbvKc0BAAAAAAAgE0l8AIAAAAAAGDUBF5bSFVdXVWfqaqjVXXgDNtfWFUfHbY/WFUr868SYDlNcYx+Z1U9WlWfrKr7q+pli6gTYFmtdZye6Pf9VdVVtXee9QEsu2mO01V1/fCe+pGq+sV51wiwzKb43OOlVfWxqvrt4bOPNy+iTng+7uG1RVTVeUl+N8kbkhxP8lCSt3X3oxN9/naSv9Tdf7Oqbkjyfd39AwspGGCJTHmM/t4kD3b3V6vqbyW5wjEaYD6mOU4P/b4lyd1Jzk9yU3cfmXetAMtoyvfTe5LckeR13f2lqvrT3f30QgoGWDJTHqcPJfnt7v5AVb08yT3dvbKIeuFsXOG1dVye5Gh3P9Hdf5Dk9iTXntbn2iS3Dct3JrmyqmqONQIsqzWP0d39se7+6rD6QJJL5lwjwDKb5r10krw3yU8l+e/zLA6AqY7Tfz3Jz3X3l5JE2AUwV9McpzvJtw7L35bkP8+xPpiKwGvruDjJkxPrx4e2M/bp7meTfCXJS+ZSHcBym+YYPenGJL8204oAmLTmcbqqXpXk0u6+e56FAZBkuvfT35HkO6rq31fVA1V19dyqA2Ca4/Q/SPKDVXU8yT1JfnQ+pcH0diy6AADYTqrqB5PsTfI9i64FgFVV9YIkP5Pk7QsuBYCz25FkT5Irsjpbwm9U1V/s7i8vtCoATnlbkg919z+uqu9O8i+r6ru6++uLLgxOcYXX1nEiyaUT65cMbWfsU1U7snrp6O/PpTqA5TbNMTpV9fokfz/JW7r7a3OqDYC1j9PfkuS7kny8qo4leU2Sw1W1d24VAiy3ad5PH09yuLv/sLs/m9V7yeyZU30Ay26a4/SNWb3XYrr7N5N8U5Jdc6kOpiTw2joeSrKnqi6rqvOT3JDk8Gl9DifZNyy/Ncmvd3fPsUaAZbXmMbqqXpnk57MadrnfAMB8Pe9xuru/0t27untluLH2A1k9Xh9ZTLkAS2eazzz+76xe3ZWq2pXVKQ6fmGeRAEtsmuP07yW5Mkmq6juzGnidnGuVsAaB1xYx3JPrpiT3JnksyR3d/UhVvaeq3jJ0uyXJS6rqaJJ3JjmwmGoBlsuUx+ifTvKiJL9UVZ+oqtPfGAIwI1MepwFYkCmP0/cm+f2qejTJx5L8H91tVhuAOZjyOP3jSf56Vf1Oko8kebuLMdhqys8kAAAAAAAAY+YKLwAAAAAAAEZN4AUAAAAAAMCoCbwAAAAAAAAYNYEXAAAAAAAAoybwAgAAAAAAYNQEXgAAAAAAAIyawAsAAAAAAIBR27HoAp7Prl27emVlZdFlAAAAAAAAMGcPP/zwF7t79zR9t3TgtbKykiNHjiy6DAAAAAAAAOasqj43bV9TGgIAAAAAADBqAi8AAAAAAABGTeAFAAAAAADAqG3pe3gBAABsBSsH7l50CXN37OA1iy4BAABgaq7wAgAAAACkQ2DuAAAgAElEQVQAYNQEXgAAAAAAAIyawAsAAAAAAIBRE3gBAAAAAAAwagIvAAAAAAAARk3gBQAAAAAAwKgJvAAAAAAAABg1gRcAAAAAAACjJvACAAAAAABg1AReAAAAAAAAjJrACwAAAAAAgFETeAEAAAAAADBqAi8AAAAAAABGTeAFAAAAAADAqAm8AAAAAAAAGDWBFwAAAAAAAKMm8AIAAAAAAGDUBF4AAAAAAACMmsALAAAAAACAUVsz8KqqW6vq6ar69ETbP6iqE1X1ieHrzRPb3l1VR6vqM1X1xon2q4e2o1V1YPNfCgAAAAAAAMtomiu8PpTk6jO0v6+7XzF83ZMkVfXyJDck+QvDY/5pVZ1XVecl+bkkb0ry8iRvG/oCAAAAAADAhuxYq0N3/0ZVrUz5fNcmub27v5bks1V1NMnlw7aj3f1EklTV7UPfR8+5YgAAAAAAAJiwkXt43VRVnxymPNw5tF2c5MmJPseHtrO1AwAAAAAAwIasN/D6QJI/m+QVSZ5K8o83q6Cq2l9VR6rqyMmTJzfraQEAAAAAANim1hV4dfcXuvuPuvvrSf55/v9pC08kuXSi6yVD29naz/Tch7p7b3fv3b1793rKAwAAAAAAYImsK/CqqosmVr8vyaeH5cNJbqiqF1bVZUn2JPkPSR5KsqeqLquq85PcMPQFAAAAAACADdmxVoeq+kiSK5LsqqrjSW5OckVVvSJJJzmW5G8kSXc/UlV3JHk0ybNJ3tHdfzQ8z01J7k1yXpJbu/uRTX81AAAAAAAALJ01A6/uftsZmm95nv4/meQnz9B+T5J7zqk6AAAAAAAAWMO6pjQEAAAAAACArULgBQAAAAAAwKgJvAAAAAAAABg1gRcAAAAAAACjJvACAAAAAABg1AReAAAAAAAAjJrACwAAAAAAgFETeAEAAAAAADBqAi8AAAAAAABGTeAFAAAAAADAqAm8AAAAAAAAGDWBFwAAAAAAAKMm8AIAAAAAAGDUBF4AAAAAAACMmsALAAAAAACAURN4AQAAAAAAMGoCLwAAAAAAAEZN4AUAAAAAAMCoCbwAAAAAAAAYNYEXAAAAAAAAoybwAgAAAAAAYNTWDLyq6taqerqqPj3RdkFV3VdVjw/fdw7tVVU/W1VHq+qTVfWqicfsG/o/XlX7ZvNyAAAAAAAAWDbTXOH1oSRXn9Z2IMn93b0nyf3DepK8Kcme4Wt/kg8kqwFZkpuTvDrJ5UluPhWSAQAAAAAAwEasGXh1928keea05muT3DYs35bkuon2D/eqB5K8uKouSvLGJPd19zPd/aUk9+W5IRoAAAAAAACcs/Xew+vC7n5qWP58kguH5YuTPDnR7/jQdrb256iq/VV1pKqOnDx5cp3lAQAAAAAAsCzWG3j9se7uJL0JtZx6vkPdvbe79+7evXuznhYAAAAAAIBtar2B1xeGqQozfH96aD+R5NKJfpcMbWdrBwAAAAAAgA1Zb+B1OMm+YXlfkrsm2n+4Vr0myVeGqQ/vTXJVVe2sqp1JrhraAAAAAAAAYEN2rNWhqj6S5Ioku6rqeJKbkxxMckdV3Zjkc0muH7rfk+TNSY4m+WqSH0mS7n6mqt6b5KGh33u6+5lNfB0AAAAAAAAsqTUDr+5+21k2XXmGvp3kHWd5nluT3HpO1QEAAAAAAMAa1julIQAAAAAAAGwJAi8AAAAAAABGTeAFAAAAAADAqAm8AAAAAAAAGDWBFwAAAAAAAKMm8AIAAAAAAGDUBF4AAAAAAACMmsALAAAAAACAURN4AQAAAAAAMGoCLwAAAAAAAEZN4AUAAAAAAMCoCbwAAAAAAAAYNYEXAAAAAAAAoybwAgAAAAAAYNQEXgAAAAAAAIyawAsAAAAAAIBRE3gBAAAAAAAwagIvAAAAAAAARk3gBQAAAAAAwKgJvAAAAAAAABg1gRcAAAAAAACjtqHAq6qOVdWnquoTVXVkaLugqu6rqseH7zuH9qqqn62qo1X1yap61Wa8AAAAAAAAAJbbZlzh9b3d/Yru3jusH0hyf3fvSXL/sJ4kb0qyZ/jan+QDm7BvAAAAAAAAltwspjS8Nsltw/JtSa6baP9wr3ogyYur6qIZ7B8AAAAAAIAlstHAq5P8v1X1cFXtH9ou7O6nhuXPJ7lwWL44yZMTjz0+tH2DqtpfVUeq6sjJkyc3WB4AAAAAAADb3Y4NPv5/6e4TVfWnk9xXVf9xcmN3d1X1uTxhdx9KcihJ9u7de06PBQAAAAAAYPls6Aqv7j4xfH86ya8muTzJF05NVTh8f3rofiLJpRMPv2RoAwAAAAAAgHVbd+BVVd9cVd9yajnJVUk+neRwkn1Dt31J7hqWDyf54Vr1miRfmZj6EAAAAAAAANZlI1MaXpjkV6vq1PP8Yv9/7d1xsGZ1eR/w7yMr2tQoCDsEAV06otHaqMkWtY6aCCZUMoItQZzULAkZahVNS52CzR+ZMe3MapoaMnXabMAEM45AiZZNQQmiNu2MUBaLIjDIiqhLUFDBlnGqQZ/+cc/S63J3993d+77vPff9fGZ29j3n/M79PTvzu8+e9zzn9zvdn6iqW5JcVVXnJflqkrOH9tcleX2SnUm+l+TXD6FvAAAAAAAASHIIBa/uvjfJi1fY/+0kp6ywv5O8/WD7AwAAAAAAgJUc0ju8AAAAAAAAYN4UvAAAAAAAABg1BS8AAAAAAABGTcELAAAAAACAUVPwAgAAAAAAYNQUvAAAAAAAABg1BS8AAAAAAABGTcELAAAAAACAUVPwAgAAAAAAYNQ2zDsAAADWj00XXzvvEGbuvq2nzzsEYJXIYQAAMF5meAEAAAAAADBqCl4AAAAAAACMmiUNAYCZsVQUAAAAANOg4AUAMEWLWOQDgLVs0f5v9vANALAoFLwAAOAQLNqN08TNU1hPFjGHAQCwPil4AcCcuMEEwFrm/ykAAGBMFLwAWBPcVAMAAAAADpaCFwAAcEA8pAAwHouYsy29CwCLScELAAAAgHVDkQ8AFtOT5h0AAAAAAAAAHIqZz/CqqtOSXJLksCSXdvfWWcewni3aU0yeYFoMizauE2MbAAAAAOBAzLTgVVWHJflAktcl2ZXklqra3t13zjIOgLVuEYt8AAAAHJxF/A7pQVEA9jTrGV4nJ9nZ3fcmSVVdkeSMJApeAAAAAACwQBTsWU2zLngdl+Try7Z3JXnZjGNgHZEQAQAAABbPIt4TYjG49wcHb+bv8Nqfqjo/yfnD5qNVdfc84xmho5N8a95BMD313nlHsCYZ9ywi455FZNyziIx7FpWxzyIy7llExv0e3Ptb/+q9xv0Bes6kDWdd8Lo/yQnLto8f9j2uu7cl2TbLoNaTqtrR3ZvnHQfMknHPIjLuWUTGPYvIuGdRGfssIuOeRWTcs4iM++l50oz7uyXJSVV1YlUdnuScJNtnHAMAAAAAAADryExneHX3Y1V1QZLrkxyW5IPdfccsYwAAAAAAAGB9mfk7vLr7uiTXzbrfBWI5SBaRcc8iMu5ZRMY9i8i4Z1EZ+ywi455FZNyziIz7KanunncMAAAAAAAAcNBm/Q4vAAAAAAAAWFUKXiNTVb9SVXdU1Y+qavM+2p1WVXdX1c6qunjZ/hOr6uZh/5VVdfhsIodDU1XPrKobquqe4e8jV2jzC1V127I//7eqzhyO/WlVfWXZsZfM/l8BB2aScT+0++Gysb192X45n9GZMN+/pKo+O1wTfaGq3rTsmHzPaOztmn3Z8acM+XvnkM83LTv27mH/3VX1S7OMGw7FBOP+wqq6c8jvN1bVc5YdW/GaB9a6Ccb9uVX10LLx/ZvLjm0Zrovuqaots40cDs0EY//9y8b9l6rqkWXH5HxGp6o+WFUPVtUX93K8quoPh9+JL1TVzy47Jt+vAksajkxVvSDJj5L8UZJ3dfeOFdocluRLSV6XZFeSW5K8ubvvrKqrkny0u6+oqv+U5PPd/R9n9y+Ag1NV70vyne7eOlwkHdndF+2j/TOT7ExyfHd/r6r+NMl/7e6rZxMxHLpJx31VPdrdT1thv5zP6Ewy7qvqeUm6u++pqmcluTXJC7r7EfmesdjXNfuyNm9L8jPd/daqOifJG7v7TVX1wiQfSXJykmcl+WSS53X3D2f974ADMeG4/4UkNw/X8P8syc9395uGYyte88BaNuG4PzfJ5u6+YI9zn5lkR5LNSTpL1zw/190PzyZ6OHiTjP092r8jyUu7+zeGbTmf0amqVyd5NMmHuvtFKxx/fZJ3JHl9kpcluaS7Xybfrx4zvEamu+/q7rv30+zkJDu7+97u/kGSK5KcUVWV5LVJdt8AujzJmdOLFlbVGVkas8lkY/esJB/v7u9NNSqYrgMd94+T8xmx/Y777v5Sd98zfP7rJA8m2TizCGF1rHjNvkeb5b8PVyc5ZcjvZyS5oru/391fydJDPifPKG44FPsd99396WXX8DclOX7GMcJqmyTf780vJbmhu78z3PS8IclpU4oTVtuBjv03Z+mBHhit7v6rJN/ZR5MzslQM6+6+KckRVXVs5PtVo+C1Ph2X5OvLtncN+45K8kh3P7bHfhiDY7r7geHzN5Ics5/25+SJF0r/dpgu/P6qesqqRwirb9Jx/9Sq2lFVN9WwjGfkfMbrgPJ9VZ2c5PAkX162W75nDPZ2zb5imyGffzdL+X2Sc2EtOtCxe16Sjy/bXumaB9a6Scf9Px6uX66uqhMO8FxYiyYev8PytScm+dSy3XI+69Hefi/k+1WyYd4B8ERV9ckkP7XCod/u7mtmHQ/Myr7G/vKN7u6q2ut6rMOTEX8vyfXLdr87SzdOD0+yLclFSd5zqDHDoVqlcf+c7r6/qv5Okk9V1e1ZuikKa9Iq5/s/S7Klu3807JbvAdaBqvonWVrW5zXLdj/hmqe7v7zyT4BR+YskH+nu71fVP83S7N7XzjkmmKVzkly9x/LMcj5wwBS81qDuPvUQf8T9SU5Ytn38sO/bWZomuWF4QnT3flgT9jX2q+qbVXVsdz8w3OB8cB8/6uwkH+vuv1n2s3fPFvh+Vf1JknetStBwiFZj3Hf3/cPf91bVZ5K8NMmfR85njVqNcV9VT09ybZYeCLpp2c+W7xmLvV2zr9RmV1VtSPKMLF3TT3IurEUTjd2qOjVLD0G8pru/v3v/Xq553PxkrdvvuO/uby/bvDTJ+5ad+/N7nPuZVY8QpuNArlfOSfL25TvkfNapvf1eyPerxJKG69MtSU6qqhOr6vAs/aexvbs7yaez9G6jJNmSxIwxxmJ7lsZssv+x+4R1n4ebprvfa3Rmki9OIUZYbfsd91V15O4l26rq6CSvTHKnnM+ITTLuD0/ysSytfX71Hsfke8ZixWv2Pdos/304K8mnhvy+Pck5VfWUqjoxyUlJ/ueM4oZDsd9xX1UvTfJHSd7Q3Q8u27/iNc/MIoeDN8m4P3bZ5huS3DV8vj7JLw7j/8gkv5gfX8kE1rJJrnVSVT+d5Mgkn122T85nvdqe5NdqycuTfHd4aFO+XyUKXiNTVW+sql1JXpHk2qq6ftj/rKq6Lnl8ff8LsvRLcVeSq7r7juFHXJTkwqramaX1/y+b9b8BDtLWJK+rqnuSnDpsp6o2V9WluxtV1aYsPSnx3/Y4/8PDMm+3Jzk6yb+ZQcxwqCYZ9y9IsqOqPp+lAtfW7t79RUDOZ4wmGfdnJ3l1knOr6rbhz0uGY/I9o7C3a/aqek9VvWFodlmSo4Y8fmGSi4dz70hyVZZu/Hwiydv3WAII1qQJx/3vJXlakv885PfdN0f3dc0Da9aE4/6dVXXHML7fmeTc4dzvJPndLBUObknynmEfrHkTjv1kqRB2xfBQz25yPqNUVR/JUvH2+VW1q6rOq6q3VtVbhybXJbk3yc4kf5zkbYl8v5rqx3MJAAAAAAAAjIsZXgAAAAAAAIyaghcAAAAAAACjpuAFAAAAAADAqCl4AQAAAAAAMGoKXgAAAAAAAIyaghcAAAAAAACjpuAFAAAAAADAqCl4AQAAAAAAMGob5h3Avhx99NG9adOmeYcBAAAAAADAjN16663f6u6Nk7Rd0wWvTZs2ZceOHfMOAwAAAAAAgBmrqq9O2taShgAAAAAAAIyaghcAAAAAAACjpuAFAAAAAADAqK3pd3gBAAAAAGvXpouvnUu/9209fS79ArB2meEFAAAAAADAqCl4AQAAAAAAMGoKXgAAAAAAAIyaghcAAAAAAACjpuAFAAAAAADAqCl4AQAAAAAAMGoKXgAAAAAAAIyaghcAAAAAAACjpuAFAAAAAADAqCl4AQAAAAAAMGoKXgAAAAAAAIyaghcAAAAAAACjpuAFAAAAAADAqE2t4FVV/6Kq7qiqL1bVR6rqqVV1YlXdXFU7q+rKqjp8Wv0DAAAAAACwGKZS8Kqq45K8M8nm7n5RksOSnJPkvUne393PTfJwkvOm0T8AAAAAAACLY5pLGm5I8reqakOSn0jyQJLXJrl6OH55kjOn2D8AAAAAAAALYCoFr+6+P8m/S/K1LBW6vpvk1iSPdPdjQ7NdSY7b89yqOr+qdlTVjoceemga4QEAAAAAALCOTGtJwyOTnJHkxCTPSvK3k5w2ybndva27N3f35o0bN04jPAAAAAAAANaRaS1peGqSr3T3Q939N0k+muSVSY4YljhMkuOT3D+l/gEAAAAAAFgQ0yp4fS3Jy6vqJ6qqkpyS5M4kn05y1tBmS5JrptQ/AAAAAAAAC2Ja7/C6OcnVST6X5Pahn21JLkpyYVXtTHJUksum0T8AAAAAAACLY8P+mxyc7v6dJL+zx+57k5w8rT4BAAAAAABYPNNa0hAAAAAAAABmQsELAAAAAACAUVPwAgAAAAAAYNQUvAAAAAAAABg1BS8AAAAAAABGTcELAAAAAACAUVPwAgAAAAAAYNQUvAAAAAAAABi1DfMOAAAAAIDp2HTxtXPr+76tp8+tbwBg8ZjhBQAAAAAAwKgpeAEAAAAAADBqCl4AAAAAAACMmnd4AQAAALBueG8ZACwmM7wAAAAAAAAYtanN8KqqI5JcmuRFSTrJbyS5O8mVSTYluS/J2d398LRiAAAAAPZuXjNhzIIBAGC1TXOG1yVJPtHdP53kxUnuSnJxkhu7+6QkNw7bAAAAAAAAcNCmUvCqqmckeXWSy5Kku3/Q3Y8kOSPJ5UOzy5OcOY3+AQAAAAAAWBzTWtLwxCQPJfmTqnpxkluT/FaSY7r7gaHNN5IcM6X+F5blKAAAAAAAgEUzrYLXhiQ/m+Qd3X1zVV2SPZYv7O6uqt7zxKo6P8n5SfLsZz97SuEBAAAA8zKvhzUTD2wCAKxX03qH164ku7r75mH76iwVwL5ZVccmyfD3g3ue2N3buntzd2/euHHjlMIDAAAAAABgvZhKwau7v5Hk61X1/GHXKUnuTLI9yZZh35Yk10yjfwAAAAAAABbHtJY0TJJ3JPlwVR2e5N4kv56lAttVVXVekq8mOXuK/QMAAAAAALAAplbw6u7bkmxe4dAp0+oTAAAAAACAxTOtd3gBAAAAAADATCh4AQAAAAAAMGoKXgAAAAAAAIza1N7hBQAAAACLZNPF186l3/u2nj6XfgFgLTHDCwAAAAAAgFFT8AIAAAAAAGDUFLwAAAAAAAAYNe/wAgAA4Am8hwYAABgTBS8AAAAAYFQ8mAHAnhS8AACA0XBzi2kyvgAAYLy8wwsAAAAAAIBRU/ACAAAAAABg1CxpCAAAAAAjNq8lWQFgLTHDCwAAAAAAgFEzwwsAAAAAYAKLOJvuvq2nzzsEgIlMreBVVYcl2ZHk/u7+5ao6MckVSY5KcmuSt3T3D6bVPwAAAMBasYg3yQEAZmmaSxr+VpK7lm2/N8n7u/u5SR5Oct4U+wYAAAAAAGBBTKXgVVXHJzk9yaXDdiV5bZKrhyaXJzlzGn0DAAAAAACwWKa1pOEfJPlXSX5y2D4qySPd/diwvSvJcVPqGwAAAGBFlhYEAFifVn2GV1X9cpIHu/vWgzz//KraUVU7HnrooVWODgAAAAAAgPVmGjO8XpnkDVX1+iRPTfL0JJckOaKqNgyzvI5Pcv9KJ3f3tiTbkmTz5s09hfgAAAAAAJjAPGfG3rf19Ln1DYzPqs/w6u53d/fx3b0pyTlJPtXdv5rk00nOGpptSXLNavcNAAAAAADA4ln1gtc+XJTkwqramaV3el02w74BAAAAAABYp6axpOHjuvszST4zfL43ycnT7A8AAAAAAIDFM8sZXgAAAAAAALDqpjrDCwAAYD2Y18vavah9McxrfAEAwHpihhcAAAAAAACjZoYXAAAAAAAsMCsasB6Y4QUAAAAAAMCoKXgBAAAAAAAwapY0BAAAAABgzbHMHnAgFLwAgJnxZQUAAABYC9yjWH8UvAAA4BDM60vSPPmCxjQt4u8UAABw6BS8AAAA1ijFHwAAgMkoeAEAAAdEEQYAAFgNvluwmp407wAAAAAAAADgUJjhBQAAAAAAA7OOYJzM8AIAAAAAAGDUFLwAAAAAAAAYtaksaVhVJyT5UJJjknSSbd19SVU9M8mVSTYluS/J2d398DRiAAAAAGB+LAkGAMzStN7h9ViSf9ndn6uqn0xya1XdkOTcJDd299aqujjJxUkumlIMAMAK3HhgvTK2AQAAYHFNZUnD7n6guz83fP4/Se5KclySM5JcPjS7PMmZ0+gfAAAAAACAxTH1d3hV1aYkL01yc5JjuvuB4dA3srTkIQAAAAAAABy0qRa8quppSf48yT/v7v+9/Fh3d5be77XnOedX1Y6q2vHQQw9NMzwAAAAAAADWgakVvKrqyVkqdn24uz867P5mVR07HD82yYN7ntfd27p7c3dv3rhx47TCAwAAAAAAYJ2YSsGrqirJZUnu6u5/v+zQ9iRbhs9bklwzjf4BAAAAAABYHBum9HNfmeQtSW6vqtuGff86ydYkV1XVeUm+muTsKfUPAAAAAADAgphKwau7/0eS2svhU6bRJwAAAAAAAItpau/wAgAAAAAAgFlQ8AIAAAAAAGDUFLwAAAAAAAAYtam8wwsAgMW06eJr5x0CAAAAsIAUvACAdW+eRZj7tp4+t74BAAAAFoUlDQEAAAAAABg1BS8AAAAAAABGTcELAAAAAACAUfMOL2DN8+4dAAAAAAD2RcELAGCK5lW0V7AHAAAAFomCFwDMyTxnLwIAAADAeuIdXgAAAAAAAIyaghcAAAAAAACjZklDABaaZQVZr4xtAAAAYJGY4QUAAAAAAMCozXyGV1WdluSSJIclubS7t846BhizeT6xf9/W0+fWN7NhfAEAAAAAYzTTgldVHZbkA0lel2RXkluqant33znLOAAmNa8CkOIPAAAAAMDkZr2k4clJdnb3vd39gyRXJDljxjEAAAAAAACwjsx6ScPjknx92fauJC+bcQxMgVkwAAAAAADAvFR3z66zqrOSnNbdvzlsvyXJy7r7gmVtzk9y/rD5/CR3zyzA9eHoJN+adxAAh0AeA8ZOHgPGTh4Dxk4eA8ZOHvv/ntPdGydpOOsZXvcnOWHZ9vHDvsd197Yk22YZ1HpSVTu6e/O84wA4WPIYMHbyGDB28hgwdvIYMHby2MGZ9Tu8bklyUlWdWFWHJzknyfYZxwAAAAAAAMA6MtMZXt39WFVdkOT6JIcl+WB33zHLGAAAAAAAAFhfZr2kYbr7uiTXzbrfBWI5SGDs5DFg7OQxYOzkMWDs5DFg7OSxg1DdPe8YAAAAAAAA4KDN+h1eAAAAAAAAsKoUvEauqn6lqu6oqh9V1eZ9tDutqu6uqp1VdfEsYwTYl6p6ZlXdUFX3DH8fuZd27xvy3V1V9YdVVbOOFWAlB5DHnl1VfznksTuratNsIwVY2aR5bGj79KraVVX/YZYxAuzLJHmsql5SVZ8dvld+oareNI9YAZbb3337qnpKVV05HL/Z98h9U/Aavy8m+UdJ/mpvDarqsCQfSPIPk7wwyZur6oWzCQ9gvy5OcmN3n5TkxmH7x1TVP0jyyiQ/k+RFSf5+ktfMMkiAfdhvHht8KMnvdfcLkpyc5MEZxQewP5PmsST53ezj+yfAnEySx76X5Ne6++8mOS3JH1TVETOMEeDHTHjf/rwkD3f3c5O8P8l7ZxvluCh4jVx339Xdd++n2clJdnb3vd39gyRXJDlj+tEBTOSMJJcPny9PcuYKbTrJU5McnuQpSZ6c5JsziQ5g//abx4YvLRu6+4Yk6e5Hu/t7swsRYJ8muR5LVf1ckmOS/OWM4gKY1H7zWHd/qbvvGT7/dZYePto4swgBnmiS+/bL89vVSU6x6tHeKXgthuOSfH3Z9q5hH8BacEx3PzB8/kaWbqL8mO7+bJJPJ3lg+HN9d981uxAB9mm/eSzJ85I8UlUfrar/VVW/NzzNB7AW7DePVdWTkvx+knfNMjCACU1yPfa4qjo5Sw9UfnnagQHswyT37R9v092PJflukqNmEt0IbZh3AOxfVX0yyU+tcOi3u/uaWccDcKD2lceWb3R3V1WvcP5zk7wgyfHDrhuq6lXd/d9XPViAFRxqHsvSdferkrw0ydeSXJnk3CSXrW6kACtbhTz2tiTXdfcuDxUD87AKeWz3zzk2yZ8l2dLdP1rdKAGYJwWvEejuUw/xR9yf5IRl28cP+wBmYl95rKq+WVXHdvcDwxePld5p88YkN3X3o8M5H0/yiiQKXsBMrEIe25Xktu6+dzjnvyR5eRS8gBlZhTz2iiSvqqq3JXlaksOr6tHu3tf7vgBWzSrksVTV05Ncm6WHyG+aUqgAk5rkvv3uNruqakOSZyT59mzCGx9LGi6GW5KcVFUnVtXhSc5Jsn3OMQHstj3JluHzliQrzVz9WpLXVNWGqnpyktcksaQhsFZMksduSXJEVe1+T8Rrk9w5g9gAJrHfPNbdv9rdz+7uTVla1vBDil3AGrLfPDbcE/tYlvLX1TOMDWBvJrlvvzy/nW8p2ogAAAEASURBVJXkU92911msi07Ba+Sq6o1VtStLT9tdW1XXD/ufVVXXJY+v7XlBkuuzdIP4qu6+Y14xA+xha5LXVdU9SU4dtlNVm6vq0qHN1VlaW/32JJ9P8vnu/ot5BAuwgv3mse7+YZZuEN9YVbcnqSR/PKd4AfY0yfUYwFo2SR47O8mrk5xbVbcNf14yn3AB9n7fvqreU1VvGJpdluSoqtqZ5MIkHjjah1IMBAAAAAAAYMzM8AIAAAAAAGDUFLwAAAAAAAAYNQUvAAAAAAAARk3BCwAAAAAAgFFT8AIAAAAAAGDUFLwAAAAAAAAYNQUvAAAAAAAARk3BCwAAAAAAgFH7fzDSf2t6Cs+CAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2160x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# delete useless data\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "f,axes = plt.subplots(nrows=4, ncols=1,figsize=(30,10))\n",
    "\n",
    "\n",
    "# remove noisy data\n",
    "angle_data = np.array(driving_data_left)[:,3].astype(\"float\")\n",
    "n, bins, patches = axes[0].hist(angle_data, bins=25)\n",
    "print(\"the number of driving data on left lane before delete :\"+str(len(driving_data_left)))\n",
    "noise_left = np.where(np.zeros_like(angle_data)>=angle_data)\n",
    "driving_data_left=np.delete(driving_data_left,noise_left,axis=0)\n",
    "print(\"the number of driving data on left lane after delete :\"+str(len(driving_data_left)))\n",
    "\n",
    "\n",
    "# remove noisy data\n",
    "angle_data = np.array(driving_data_right)[:,3].astype(\"float\")\n",
    "n, bins, patches = axes[2].hist(angle_data, bins=25)\n",
    "print(\"the number of driving data on right lane before delete :\"+str(len(driving_data_right)))\n",
    "noise_right = np.where(np.zeros_like(angle_data)<=angle_data)\n",
    "driving_data_right=np.delete(driving_data_right,noise_right,axis=0)\n",
    "print(\"the number of driving data on right lane after delete :\"+str(len(driving_data_right)))\n",
    "\n",
    "n, bins, patches = axes[1].hist(driving_data_left[:,3].astype(\"float\"), bins=50)\n",
    "n, bins, patches = axes[3].hist(driving_data_right[:,3].astype(\"float\"), bins=50)\n",
    "print(np.shape(driving_data_center))\n",
    "print(np.shape(driving_data_left))\n",
    "print(np.shape(driving_data_right))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10665\n",
      "3305.0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_1 (Cropping2D)    (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 33, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 33, 158, 24)       96        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 33, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 15, 77, 36)        144       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 6, 37, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 6, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 4, 35, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 2, 33, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4224)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               422500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,120,633\n",
      "Trainable params: 560,191\n",
      "Non-trainable params: 560,442\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "74/74 [==============================] - 32s 432ms/step - loss: 0.0182\n",
      "295/295 [==============================] - 147s 499ms/step - loss: 0.0194 - val_loss: 0.0182\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 31s 417ms/step - loss: 0.0182\n",
      "295/295 [==============================] - 145s 490ms/step - loss: 0.0188 - val_loss: 0.0182\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 31s 414ms/step - loss: 0.0182\n",
      "295/295 [==============================] - 145s 491ms/step - loss: 0.0187 - val_loss: 0.0182\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 31s 419ms/step - loss: 0.0181\n",
      "295/295 [==============================] - 145s 491ms/step - loss: 0.0187 - val_loss: 0.0181\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - 31s 423ms/step - loss: 0.0181\n",
      "295/295 [==============================] - 147s 497ms/step - loss: 0.0186 - val_loss: 0.0181\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 31s 419ms/step - loss: 0.0180\n",
      "295/295 [==============================] - 146s 494ms/step - loss: 0.0186 - val_loss: 0.0180\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 31s 424ms/step - loss: 0.0180\n",
      "295/295 [==============================] - 147s 499ms/step - loss: 0.0186 - val_loss: 0.0180\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 31s 416ms/step - loss: 0.0179\n",
      "295/295 [==============================] - 146s 494ms/step - loss: 0.0186 - val_loss: 0.0179\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 31s 419ms/step - loss: 0.0179\n",
      "295/295 [==============================] - 145s 493ms/step - loss: 0.0186 - val_loss: 0.0179\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 31s 422ms/step - loss: 0.0179\n",
      "295/295 [==============================] - 146s 494ms/step - loss: 0.0185 - val_loss: 0.0179\n",
      "1/8 finish!\n",
      "10665\n",
      "5758.333333333333\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_1 (Cropping2D)    (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 33, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 33, 158, 24)       96        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 33, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 15, 77, 36)        144       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 6, 37, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 6, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 4, 35, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 2, 33, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4224)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               422500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,120,633\n",
      "Trainable params: 560,191\n",
      "Non-trainable params: 560,442\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 [==============================] - 25s 436ms/step - loss: 0.0200\n",
      "225/225 [==============================] - 122s 540ms/step - loss: 0.0224 - val_loss: 0.0200\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 25s 443ms/step - loss: 0.0199\n",
      "225/225 [==============================] - 113s 504ms/step - loss: 0.0218 - val_loss: 0.0199\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 26s 449ms/step - loss: 0.0198\n",
      "225/225 [==============================] - 116s 514ms/step - loss: 0.0217 - val_loss: 0.0198\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 25s 431ms/step - loss: 0.0197\n",
      "225/225 [==============================] - 115s 509ms/step - loss: 0.0216 - val_loss: 0.0197\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 25s 433ms/step - loss: 0.0197\n",
      "225/225 [==============================] - 114s 508ms/step - loss: 0.0216 - val_loss: 0.0197\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 25s 442ms/step - loss: 0.0196\n",
      "225/225 [==============================] - 115s 509ms/step - loss: 0.0216 - val_loss: 0.0196\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 25s 434ms/step - loss: 0.0196\n",
      "225/225 [==============================] - 113s 504ms/step - loss: 0.0216 - val_loss: 0.0196\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 25s 433ms/step - loss: 0.0196\n",
      "225/225 [==============================] - 114s 508ms/step - loss: 0.0215 - val_loss: 0.0196\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 25s 438ms/step - loss: 0.0195\n",
      "225/225 [==============================] - 114s 508ms/step - loss: 0.0215 - val_loss: 0.0195\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 25s 434ms/step - loss: 0.0195\n",
      "225/225 [==============================] - 114s 508ms/step - loss: 0.0215 - val_loss: 0.0195\n",
      "2/8 finish!\n",
      "10665\n",
      "6985.0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_1 (Cropping2D)    (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 33, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 33, 158, 24)       96        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 33, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 15, 77, 36)        144       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 6, 37, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 6, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 4, 35, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 2, 33, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4224)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               422500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,120,633\n",
      "Trainable params: 560,191\n",
      "Non-trainable params: 560,442\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 22s 456ms/step - loss: 0.0249\n",
      "190/190 [==============================] - 106s 557ms/step - loss: 0.0250 - val_loss: 0.0249\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 21s 440ms/step - loss: 0.0243\n",
      "190/190 [==============================] - 97s 512ms/step - loss: 0.0245 - val_loss: 0.0243\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 22s 453ms/step - loss: 0.0241\n",
      "190/190 [==============================] - 98s 515ms/step - loss: 0.0244 - val_loss: 0.0241\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 22s 457ms/step - loss: 0.0240\n",
      "190/190 [==============================] - 98s 515ms/step - loss: 0.0243 - val_loss: 0.0240\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.0240\n",
      "190/190 [==============================] - 97s 511ms/step - loss: 0.0243 - val_loss: 0.0240\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 21s 445ms/step - loss: 0.0239\n",
      "190/190 [==============================] - 98s 514ms/step - loss: 0.0242 - val_loss: 0.0239\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.0239\n",
      "190/190 [==============================] - 97s 510ms/step - loss: 0.0242 - val_loss: 0.0239\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 22s 450ms/step - loss: 0.0239\n",
      "190/190 [==============================] - 98s 515ms/step - loss: 0.0242 - val_loss: 0.0239\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.0239\n",
      "190/190 [==============================] - 99s 521ms/step - loss: 0.0241 - val_loss: 0.0239\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.0238\n",
      "190/190 [==============================] - 96s 508ms/step - loss: 0.0241 - val_loss: 0.0238\n",
      "3/8 finish!\n",
      "10665\n",
      "7721.0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_1 (Cropping2D)    (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 33, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 33, 158, 24)       96        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 33, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 15, 77, 36)        144       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 6, 37, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 6, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 4, 35, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 2, 33, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4224)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               422500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,120,633\n",
      "Trainable params: 560,191\n",
      "Non-trainable params: 560,442\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "43/43 [==============================] - 20s 465ms/step - loss: 0.0246\n",
      "169/169 [==============================] - 99s 585ms/step - loss: 0.0271 - val_loss: 0.0246\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 20s 455ms/step - loss: 0.0237\n",
      "169/169 [==============================] - 89s 529ms/step - loss: 0.0263 - val_loss: 0.0237\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 20s 474ms/step - loss: 0.0237\n",
      "169/169 [==============================] - 90s 531ms/step - loss: 0.0258 - val_loss: 0.0237\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 20s 469ms/step - loss: 0.0237\n",
      "169/169 [==============================] - 89s 527ms/step - loss: 0.0257 - val_loss: 0.0237\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 20s 459ms/step - loss: 0.0237\n",
      "169/169 [==============================] - 89s 527ms/step - loss: 0.0257 - val_loss: 0.0237\n",
      "4/8 finish!\n",
      "10665\n",
      "8211.666666666666\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_1 (Cropping2D)    (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 33, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 33, 158, 24)       96        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 33, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 15, 77, 36)        144       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 6, 37, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 6, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 4, 35, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 2, 33, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4224)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               422500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,120,633\n",
      "Trainable params: 560,191\n",
      "Non-trainable params: 560,442\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 19s 480ms/step - loss: 0.0327\n",
      "155/155 [==============================] - 92s 591ms/step - loss: 0.0274 - val_loss: 0.0327\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 19s 476ms/step - loss: 0.0300\n",
      "155/155 [==============================] - 84s 539ms/step - loss: 0.0269 - val_loss: 0.0300\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 19s 480ms/step - loss: 0.0297\n",
      "155/155 [==============================] - 83s 533ms/step - loss: 0.0266 - val_loss: 0.0297\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 19s 475ms/step - loss: 0.0296\n",
      "155/155 [==============================] - 83s 536ms/step - loss: 0.0264 - val_loss: 0.0296\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 19s 486ms/step - loss: 0.0296\n",
      "155/155 [==============================] - 83s 536ms/step - loss: 0.0263 - val_loss: 0.0296\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 19s 480ms/step - loss: 0.0297\n",
      "155/155 [==============================] - 83s 533ms/step - loss: 0.0263 - val_loss: 0.0297\n",
      "5/8 finish!\n",
      "10665\n",
      "8562.142857142857\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_1 (Cropping2D)    (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 33, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 33, 158, 24)       96        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 33, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 15, 77, 36)        144       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 6, 37, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 6, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 4, 35, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 2, 33, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4224)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               422500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,120,633\n",
      "Trainable params: 560,191\n",
      "Non-trainable params: 560,442\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37/37 [==============================] - 17s 470ms/step - loss: 0.0305\n",
      "144/144 [==============================] - 89s 616ms/step - loss: 0.0280 - val_loss: 0.0305\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 17s 466ms/step - loss: 0.0304\n",
      "144/144 [==============================] - 77s 535ms/step - loss: 0.0277 - val_loss: 0.0304\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 18s 482ms/step - loss: 0.0304\n",
      "144/144 [==============================] - 78s 543ms/step - loss: 0.0276 - val_loss: 0.0304\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 18s 479ms/step - loss: 0.0303\n",
      "144/144 [==============================] - 77s 536ms/step - loss: 0.0276 - val_loss: 0.0303\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 18s 481ms/step - loss: 0.0303\n",
      "144/144 [==============================] - 78s 543ms/step - loss: 0.0275 - val_loss: 0.0303\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 18s 478ms/step - loss: 0.0303\n",
      "144/144 [==============================] - 78s 540ms/step - loss: 0.0275 - val_loss: 0.0303\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 17s 461ms/step - loss: 0.0303\n",
      "144/144 [==============================] - 77s 538ms/step - loss: 0.0275 - val_loss: 0.0303\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 18s 478ms/step - loss: 0.0302\n",
      "144/144 [==============================] - 78s 540ms/step - loss: 0.0275 - val_loss: 0.0302\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 18s 495ms/step - loss: 0.0302\n",
      "144/144 [==============================] - 79s 548ms/step - loss: 0.0275 - val_loss: 0.0302\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 20s 529ms/step - loss: 0.0302\n",
      "144/144 [==============================] - 86s 595ms/step - loss: 0.0275 - val_loss: 0.0302\n",
      "6/8 finish!\n",
      "10665\n",
      "8825.0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_1 (Cropping2D)    (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 33, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 33, 158, 24)       96        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 33, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 15, 77, 36)        144       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 6, 37, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 6, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 4, 35, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 2, 33, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4224)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               422500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,120,633\n",
      "Trainable params: 560,191\n",
      "Non-trainable params: 560,442\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "35/35 [==============================] - 18s 515ms/step - loss: 0.0240\n",
      "137/137 [==============================] - 91s 668ms/step - loss: 0.0313 - val_loss: 0.0240\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 17s 482ms/step - loss: 0.0238\n",
      "137/137 [==============================] - 74s 542ms/step - loss: 0.0304 - val_loss: 0.0238\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 17s 487ms/step - loss: 0.0237\n",
      "137/137 [==============================] - 74s 542ms/step - loss: 0.0303 - val_loss: 0.0237\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 17s 490ms/step - loss: 0.0236\n",
      "137/137 [==============================] - 75s 545ms/step - loss: 0.0302 - val_loss: 0.0236\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 17s 489ms/step - loss: 0.0236\n",
      "137/137 [==============================] - 75s 549ms/step - loss: 0.0302 - val_loss: 0.0236\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 17s 484ms/step - loss: 0.0236\n",
      "137/137 [==============================] - 74s 542ms/step - loss: 0.0302 - val_loss: 0.0236\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 17s 491ms/step - loss: 0.0236\n",
      "137/137 [==============================] - 75s 550ms/step - loss: 0.0301 - val_loss: 0.0236\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 17s 493ms/step - loss: 0.0235\n",
      "137/137 [==============================] - 75s 547ms/step - loss: 0.0301 - val_loss: 0.0235\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 17s 480ms/step - loss: 0.0235\n",
      "137/137 [==============================] - 75s 549ms/step - loss: 0.0301 - val_loss: 0.0235\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 17s 483ms/step - loss: 0.0235\n",
      "137/137 [==============================] - 75s 545ms/step - loss: 0.0301 - val_loss: 0.0235\n",
      "7/8 finish!\n",
      "10665\n",
      "9029.444444444445\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_1 (Cropping2D)    (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 70, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 33, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 33, 158, 24)       96        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 33, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 15, 77, 36)        144       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 6, 37, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 6, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 4, 35, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 2, 33, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4224)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               422500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,120,633\n",
      "Trainable params: 560,191\n",
      "Non-trainable params: 560,442\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "33/33 [==============================] - 16s 477ms/step - loss: 0.0336\n",
      "131/131 [==============================] - 74s 562ms/step - loss: 0.0302 - val_loss: 0.0336\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 15s 465ms/step - loss: 0.0334\n",
      "131/131 [==============================] - 58s 443ms/step - loss: 0.0297 - val_loss: 0.0334\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 15s 465ms/step - loss: 0.0334\n",
      "131/131 [==============================] - 58s 446ms/step - loss: 0.0295 - val_loss: 0.0334\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 15s 465ms/step - loss: 0.0334\n",
      "131/131 [==============================] - 59s 448ms/step - loss: 0.0294 - val_loss: 0.0334\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 15s 465ms/step - loss: 0.0334\n",
      "131/131 [==============================] - 58s 446ms/step - loss: 0.0294 - val_loss: 0.0334\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 15s 466ms/step - loss: 0.0334\n",
      "131/131 [==============================] - 58s 445ms/step - loss: 0.0294 - val_loss: 0.0334\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 15s 469ms/step - loss: 0.0333\n",
      "131/131 [==============================] - 59s 450ms/step - loss: 0.0293 - val_loss: 0.0333\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 15s 457ms/step - loss: 0.0333\n",
      "131/131 [==============================] - 58s 443ms/step - loss: 0.0293 - val_loss: 0.0333\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 15s 469ms/step - loss: 0.0333\n",
      "131/131 [==============================] - 58s 445ms/step - loss: 0.0293 - val_loss: 0.0333\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 15s 466ms/step - loss: 0.0333\n",
      "131/131 [==============================] - 58s 446ms/step - loss: 0.0293 - val_loss: 0.0333\n",
      "8/8 finish!\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "# this model is based on NVIDIA's Network https://devblogs.nvidia.com/deep-learning-self-driving-cars/\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten,Activation,Cropping2D\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "import math\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "## to avoid my GPU specific error.\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))\n",
    "##\n",
    "for i in range(len(alpha)):\n",
    "    print(len(driving_data_center))\n",
    "    print(len(driving_data_center)-len(driving_data_left)/alpha[i])\n",
    "    driving_data_center_modified=np.delete(driving_data_center,random.sample(list(np.arange(len(driving_data_center))), int(len(driving_data_center)-len(driving_data_left)/alpha[i])),axis=0)\n",
    "    driving_data=np.concatenate((driving_data_center_modified,driving_data_left,driving_data_right),axis=0)\n",
    "    # split data\n",
    "    train_data, validation_data = train_test_split(driving_data, test_size=0.2) \n",
    "\n",
    "    # Set our batch size\n",
    "    batch_size=28\n",
    "    height = 70\n",
    "    width = 320\n",
    "    channel =3\n",
    "    # compile and train the model using the generator function\n",
    "    train_generator = driving_data_generator(train_data, batch_size=batch_size)\n",
    "    validation_generator = driving_data_generator(validation_data, batch_size=batch_size)\n",
    "    # I chose elu as activation funciton ,because the authors said that is best in this paper. (https://arxiv.org/pdf/1511.07289v5.pdf)\n",
    "    model = load_model('./model_20190820_without_dropout.h5')\n",
    "    for j in range(len(model.layers)-2):\n",
    "        model.layers[j].trainable=False\n",
    "    #endfor\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(loss='mse',optimizer='adam')\n",
    "    model.fit_generator(train_generator,\n",
    "                steps_per_epoch=math.ceil(len(train_data)/batch_size), \n",
    "                validation_data=validation_generator, \n",
    "                validation_steps=math.ceil(len(validation_data)/batch_size), \n",
    "                epochs=10,callbacks=[EarlyStopping(patience=2)], verbose=1)\n",
    "\n",
    "    model.save('./model_alpha_{0}.h5'.format(alpha[i]*10))\n",
    "    print(\"{0}/8 finish!\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
